{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 2: Clasificador de noticias\n",
    "\n",
    "### Nombres:\n",
    "Introduce en esta celda los nombres de los dos integrantes del grupo:\\\n",
    "*Alumno 1:* DANIEL CARMONA PEDRAJAS\n",
    "*Alumno 2:* JOEL PARDO FERRERA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo: Implementar un clasificador usando el conjunto de datos recopilado de varias fuentes de internet como:\n",
    "\n",
    "- Google News que toma noticias de varios repositorios dedicados a la información\n",
    "- Periodicos:\n",
    "    - El pais\n",
    "    - ABC\n",
    "    - El confidencial\n",
    "    - 20minutos\n",
    "    - El diario\n",
    "\n",
    "Este repositorio incluye tanto las noticias en formato '.txt' donde se almacenan los cuerpos de noticia y sus correspondientes titulos, como un '.csv' donde se contiene un registro de todas las noticias donde se refleja el número de noticias, la clase a la que pertenece (deportes, salud, ciencia y politica), el número de noticia dentro de la clase correspondiente, el titulo de noticia, la ruta donde esta almacenada esa noticia, y por ultimo la URL correspondiente del repositorio de donde se ha sacado al noticia. \n",
    "\n",
    "La fechas fechas tanto de publicacion como de obtenciond e datos se ubican en Noviembre de 2022. \n",
    "\n",
    "La clase a predecir es el tipo de noticia (columna 'category' de la base de datos), a partir de los archivos '.txt'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTACION DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git config --global user.email \"jpardo0824@gmail.com\"\n",
    "# git config --global user.name \"JPardo08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (3.4.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl (9.1 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.9.3-cp39-cp39-macosx_10_9_x86_64.whl (34.3 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install spacy\n",
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import unicodedata\n",
    "#from spellchecker import SpellChecker \n",
    "#from textblob import TextBlob \n",
    "#import contractions\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CARGA DE DATOS\n",
    "Cargamos los datos en dos formatos:\n",
    "* DataFrame de pandas\n",
    "* Generador\n",
    "\n",
    "Para cargar los datos utilizamos la libreria Pandas. En la funcion impleentada, le pasamos unicmanete  la ruta del archivo csv que queramos cargar y se guarda los datos en una variable generador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yq/prfd22yn0k3gnlt89mfz3zb80000gn/T/ipykernel_2165/889524856.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df = pd.read_csv('./TextClassification/Datos/urls1.csv',';')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './TextClassification/Datos/urls1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[39myield\u001b[39;00m path1, category, extracto\n\u001b[1;32m     20\u001b[0m df_gen \u001b[39m=\u001b[39m parse(\u001b[39m'\u001b[39m\u001b[39m./TextClassification/Datos/urls1.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./TextClassification/Datos/urls1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m \u001b[39m#Visualizamos los datos\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './TextClassification/Datos/urls1.csv'"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "    # Leemos el registro\n",
    "    df = pd.read_csv(path,';')\n",
    "\n",
    "    for i in df['index']:\n",
    "    #Seleccionamos lo que nos interesa de cara a un futuro\n",
    "\n",
    "    #Cogemos las columnas que nos interesan\n",
    "        path1 = df.loc[i,'path'] # Columna de la ruta\n",
    "\n",
    "        category = df.loc[i,'category'] # Columna sub\n",
    "        \n",
    "        with open(path1, 'r') as f:\n",
    "            extracto = f.readline()\n",
    "\n",
    "\n",
    "    \n",
    "        yield path1, category, extracto\n",
    "    \n",
    "df_gen = parse('./TextClassification/Datos/urls1.csv')\n",
    "df = pd.read_csv('./TextClassification/Datos/urls1.csv',',')\n",
    "#Visualizamos los datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos los tipos\n",
    "print(type(df))\n",
    "print(type(df_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'noticia', 'link_noticia', 'web', 'usuario', 'id_usuario',\n",
       "       'fecha_envio', 'fecha_publicacion', 'meneos', 'clicks', 'comentarios',\n",
       "       'votos_positivos', 'votos_anonimos', 'votos_negativos', 'karma', 'sub',\n",
       "       'extracto'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Miramos los nombres\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos un duplicado para seleccionar lo que queremos\n",
    "df2 = df.loc[:,['noticia', 'sub','extracto']]\n",
    "\n",
    "#Eliminamos los na\n",
    "df2=df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177509, 17)\n",
      "(177363, 3)\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos cuantas fila con na hemos eliminado\n",
    "print(df.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cultura',\n",
       " 'tecnología',\n",
       " 'ocio',\n",
       " 'actualidad',\n",
       " 'mnm',\n",
       " 'Japón',\n",
       " 'escombrillos',\n",
       " 'BUAMBUSUB',\n",
       " 'ciencia',\n",
       " 'Artículos',\n",
       " 'Sucesos',\n",
       " 'softlibre',\n",
       " 'TeRespondo',\n",
       " 'Biologia',\n",
       " 'linux',\n",
       " 'BARCOS',\n",
       " 'Música',\n",
       " 'AEDE',\n",
       " 'Autorrelatos',\n",
       " 'gilipolleces',\n",
       " 'Videojuegos',\n",
       " 'astronomia',\n",
       " 'opinion',\n",
       " 'idiomas',\n",
       " 'Cocíname',\n",
       " 'movilidad',\n",
       " 'OYOYOY',\n",
       " 'Cine',\n",
       " 'Ochenteando',\n",
       " 'Psicópatas',\n",
       " 'Etimologia',\n",
       " 'SysDevs',\n",
       " 'Hemeroteca',\n",
       " 'Pregúntame',\n",
       " 'Ubuntu',\n",
       " 'trenes',\n",
       " 'Poesia',\n",
       " 'Historia',\n",
       " 'Neurociencia',\n",
       " 'mexico',\n",
       " 'MADRID',\n",
       " 'PREVENCIÓN',\n",
       " 'Galicia',\n",
       " 'retrocomp',\n",
       " 'INTERNAC',\n",
       " 'Venezuela',\n",
       " 'Abuso_Animal',\n",
       " 'Jurídicas',\n",
       " 'medicina',\n",
       " 'Visualdata',\n",
       " 'autonomos',\n",
       " 'Series',\n",
       " 'aviones',\n",
       " 'Cantabria',\n",
       " 'Bulos',\n",
       " 'salud',\n",
       " 'LGBT',\n",
       " 'SEXOLOGÍA',\n",
       " 'Alimentación',\n",
       " 'Drones',\n",
       " 'ACME',\n",
       " 'Documentales',\n",
       " 'Cómics',\n",
       " 'RaspberryPi',\n",
       " 'Libros',\n",
       " 'netsec',\n",
       " 'Podemos',\n",
       " 'mascotas',\n",
       " 'CiFi',\n",
       " 'Crianza',\n",
       " 'Encuestas',\n",
       " 'UHF',\n",
       " 'Economía',\n",
       " 'Cuba',\n",
       " 'GNU_LINUX',\n",
       " 'MAmbiente',\n",
       " 'Barcelona',\n",
       " 'Fakeame',\n",
       " 'QUEJAS',\n",
       " 'deportes',\n",
       " 'Entrevistas',\n",
       " 'veganismo',\n",
       " 'alas',\n",
       " 'STARWARS',\n",
       " 'NoMundoToday',\n",
       " 'Palabros',\n",
       " 'Лhcdss',\n",
       " 'Rusia',\n",
       " 'Hazlotumismo',\n",
       " 'museo',\n",
       " 'Preguntas',\n",
       " 'dmnm',\n",
       " 'Natación',\n",
       " 'Firefox',\n",
       " 'KKKantiPDMS',\n",
       " 'RPDC',\n",
       " 'Filosofía',\n",
       " 'ELBAÚL',\n",
       " 'IMGUR',\n",
       " 'procescatalà',\n",
       " 'RebeliónMnm',\n",
       " 'smartphone',\n",
       " 'ebola',\n",
       " 'Feminismo',\n",
       " 'OrienteMedio',\n",
       " 'Drogolegas',\n",
       " 'Fotomundo',\n",
       " 'Clicómics',\n",
       " 'Animales',\n",
       " 'android',\n",
       " 'gatos',\n",
       " 'EleccionesE',\n",
       " 'Eurovision',\n",
       " 'emnm']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos los valores de la columna sub\n",
    "clases = pd.unique(df2['sub']).tolist()\n",
    "clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>extracto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnm</th>\n",
       "      <td>135102</td>\n",
       "      <td>135102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualidad</th>\n",
       "      <td>23933</td>\n",
       "      <td>23933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultura</th>\n",
       "      <td>9544</td>\n",
       "      <td>9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tecnología</th>\n",
       "      <td>4415</td>\n",
       "      <td>4415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocio</th>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            noticia  extracto\n",
       "sub                          \n",
       "mnm          135102    135102\n",
       "actualidad    23933     23933\n",
       "cultura        9544      9544\n",
       "tecnología     4415      4415\n",
       "ocio           3435      3435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos a ver que clases tienen más peso\n",
    "frecuencias = df2.groupby('sub').count()\n",
    "frecuencias = frecuencias.sort_values('noticia',ascending=False)\n",
    "\n",
    "#Visualizamos las 5 clases con mas peso\n",
    "frecuencias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>extracto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ubuntu</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EleccionesE</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMGUR</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELBAÚL</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACME</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             noticia  extracto\n",
       "sub                           \n",
       "Ubuntu             1         1\n",
       "EleccionesE        1         1\n",
       "IMGUR              1         1\n",
       "ELBAÚL             1         1\n",
       "ACME               1         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizamos las 5 clases con menos peso\n",
    "frecuencias.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "177363\n"
     ]
    }
   ],
   "source": [
    "#Calculo de peso total de los datos.\n",
    "numero_clases_total = len(pd.unique(df2['sub']))\n",
    "print(numero_clases_total)\n",
    "\n",
    "#Numero total de noticias.\n",
    "numero_textos_total = df2.shape[0]\n",
    "print(numero_textos_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un data frame para visualizar los datos.\n",
    "frecuencias2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 21, 22, 27, 30, 34, 36, 43, 55, 63, 77, 102, 111, 3435, 4415, 9544, 23933, 135102]\n"
     ]
    }
   ],
   "source": [
    "#Vamos a ver todos los diferentes numeros de noticias. \n",
    "numero_textos_clase = pd.unique(frecuencias['noticia']).tolist() #(numero noticias)\n",
    "numero_textos_clase = sorted(numero_textos_clase)\n",
    "print(numero_textos_clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>135102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numero_Noticias\n",
       "0                 1\n",
       "1                 2\n",
       "2                 3\n",
       "3                 4\n",
       "4                 5\n",
       "5                 8\n",
       "6                 9\n",
       "7                10\n",
       "8                11\n",
       "9                12\n",
       "10               13\n",
       "11               15\n",
       "12               16\n",
       "13               21\n",
       "14               22\n",
       "15               27\n",
       "16               30\n",
       "17               34\n",
       "18               36\n",
       "19               43\n",
       "20               55\n",
       "21               63\n",
       "22               77\n",
       "23              102\n",
       "24              111\n",
       "25             3435\n",
       "26             4415\n",
       "27             9544\n",
       "28            23933\n",
       "29           135102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asignacion:\n",
    "frecuencias2['Numero_Noticias'] = numero_textos_clase\n",
    "\n",
    "#Comprobacion:\n",
    "frecuencias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              noticia  extracto\n",
      "sub                            \n",
      "Cómics              1         1\n",
      "deportes            1         1\n",
      "ebola               1         1\n",
      "Documentales        1         1\n",
      "Cuba                1         1\n",
      "aviones             1         1\n",
      "gatos               1         1\n",
      "INTERNAC            1         1\n",
      "mexico              1         1\n",
      "CiFi                1         1\n",
      "Cantabria           1         1\n",
      "mascotas            1         1\n",
      "medicina            1         1\n",
      "Biologia            1         1\n",
      "movilidad           1         1\n",
      "netsec              1         1\n",
      "opinion             1         1\n",
      "retrocomp           1         1\n",
      "smartphone          1         1\n",
      "Autorrelatos        1         1\n",
      "Animales            1         1\n",
      "veganismo           1         1\n",
      "autonomos           1         1\n",
      "Economía            1         1\n",
      "android             1         1\n",
      "Filosofía           1         1\n",
      "KKKantiPDMS         1         1\n",
      "Hazlotumismo        1         1\n",
      "Libros              1         1\n",
      "MAmbiente           1         1\n",
      "Galicia             1         1\n",
      "Natación            1         1\n",
      "Neurociencia        1         1\n",
      "GNU_LINUX           1         1\n",
      "OrienteMedio        1         1\n",
      "PREVENCIÓN          1         1\n",
      "Fotomundo           1         1\n",
      "Poesia              1         1\n",
      "Firefox             1         1\n",
      "Psicópatas          1         1\n",
      "alas                1         1\n",
      "QUEJAS              1         1\n",
      "RPDC                1         1\n",
      "RaspberryPi         1         1\n",
      "Rusia               1         1\n",
      "SEXOLOGÍA           1         1\n",
      "STARWARS            1         1\n",
      "Feminismo           1         1\n",
      "Eurovision          1         1\n",
      "Entrevistas         1         1\n",
      "Ubuntu              1         1\n",
      "EleccionesE         1         1\n",
      "IMGUR               1         1\n",
      "ELBAÚL              1         1\n",
      "ACME                1         1 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              noticia  extracto\n",
      "sub                            \n",
      "Drones              2         2\n",
      "Etimologia          2         2\n",
      "museo               2         2\n",
      "Encuestas           2         2\n",
      "AEDE                2         2\n",
      "Barcelona           2         2\n",
      "RebeliónMnm         2         2\n",
      "procescatalà        2         2\n",
      "NoMundoToday        2         2\n",
      "Venezuela           2         2\n",
      "salud               2         2\n",
      "Alimentación        2         2 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             noticia  extracto\n",
      "sub                           \n",
      "Ochenteando        3         3\n",
      "Clicómics          3         3\n",
      "Drogolegas         3         3\n",
      "MADRID             3         3 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "           noticia  extracto\n",
      "sub                         \n",
      "UHF              4         4\n",
      "LGBT             4         4\n",
      "Jurídicas        4         4\n",
      "Лhcdss           4         4\n",
      "Cine             4         4 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "           noticia  extracto\n",
      "sub                         \n",
      "Palabros         5         5\n",
      "Series           5         5\n",
      "Sucesos          5         5\n",
      "SysDevs          5         5\n",
      "Japón            5         5\n",
      "Crianza          5         5\n",
      "BUAMBUSUB        5         5 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              noticia  extracto\n",
      "sub                            \n",
      "gilipolleces        8         8\n",
      "Cocíname            8         8\n",
      "Preguntas           8         8 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      noticia  extracto\n",
      "sub                    \n",
      "dmnm        9         9 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "           noticia  extracto\n",
      "sub                         \n",
      "idiomas         10        10\n",
      "Música          10        10\n",
      "softlibre       10        10 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        noticia  extracto\n",
      "sub                      \n",
      "trenes       11        11 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         noticia  extracto\n",
      "sub                       \n",
      "Fakeame       12        12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       noticia  extracto\n",
      "sub                     \n",
      "Bulos       13        13 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          noticia  extracto\n",
      "sub                        \n",
      "Historia       15        15 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              noticia  extracto\n",
      "sub                            \n",
      "Abuso_Animal       16        16\n",
      "Videojuegos        16        16 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        noticia  extracto\n",
      "sub                      \n",
      "linux        21        21\n",
      "BARCOS       21        21 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        noticia  extracto\n",
      "sub                      \n",
      "OYOYOY       22        22 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "Visualdata       27        27 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "           noticia  extracto\n",
      "sub                         \n",
      "Artículos       30        30 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              noticia  extracto\n",
      "sub                            \n",
      "escombrillos       34        34 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "Hemeroteca       36        36 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         noticia  extracto\n",
      "sub                       \n",
      "Podemos       43        43 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "Pregúntame       55        55 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "TeRespondo       63        63 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "astronomia       77        77 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      noticia  extracto\n",
      "sub                    \n",
      "emnm      102       102 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         noticia  extracto\n",
      "sub                       \n",
      "ciencia      111       111 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      noticia  extracto\n",
      "sub                    \n",
      "ocio     3435      3435 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "tecnología     4415      4415 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         noticia  extracto\n",
      "sub                       \n",
      "cultura     9544      9544 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            noticia  extracto\n",
      "sub                          \n",
      "actualidad    23933     23933 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     noticia  extracto\n",
      "sub                   \n",
      "mnm   135102    135102 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mostramos para cada clase cuantas noticias tienen. \n",
    "clases_agrupa_nnc = []\n",
    "numeros_clases_numero_texto = [] # (numero noticias /clase)\n",
    "for i in list(numero_textos_clase):\n",
    "        a = frecuencias[frecuencias['noticia']==i]\n",
    "        noticias = a.index.values\n",
    "        numeros_clases_numero_texto.append(len(noticias))\n",
    "        clases_agrupa_nnc.append(noticias)\n",
    "        print(a, '\\n'*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Noticias</th>\n",
       "      <th>Clases</th>\n",
       "      <th>Numero_Clases</th>\n",
       "      <th>Peso_Relativo</th>\n",
       "      <th>Peso_Total_Clase%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Cómics, deportes, ebola, Documentales, Cuba, ...</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Drones, Etimologia, museo, Encuestas, AEDE, B...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Ochenteando, Clicómics, Drogolegas, MADRID]</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[UHF, LGBT, Jurídicas, Лhcdss, Cine]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Palabros, Series, Sucesos, SysDevs, Japón, Cr...</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[gilipolleces, Cocíname, Preguntas]</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>[dmnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>[idiomas, Música, softlibre]</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>[trenes]</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.006202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>[Fakeame]</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>[Bulos]</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>[Historia]</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>[Abuso_Animal, Videojuegos]</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.018042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>[linux, BARCOS]</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.023680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>[OYOYOY]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>[Visualdata]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.015223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>[Artículos]</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>[escombrillos]</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.019170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "      <td>[Hemeroteca]</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.020297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>[Podemos]</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.024244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>[Pregúntame]</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63</td>\n",
       "      <td>[TeRespondo]</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.035520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>77</td>\n",
       "      <td>[astronomia]</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.043414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>102</td>\n",
       "      <td>[emnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.057509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111</td>\n",
       "      <td>[ciencia]</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0.062584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3435</td>\n",
       "      <td>[ocio]</td>\n",
       "      <td>1</td>\n",
       "      <td>3435</td>\n",
       "      <td>1.936706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4415</td>\n",
       "      <td>[tecnología]</td>\n",
       "      <td>1</td>\n",
       "      <td>4415</td>\n",
       "      <td>2.489245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9544</td>\n",
       "      <td>[cultura]</td>\n",
       "      <td>1</td>\n",
       "      <td>9544</td>\n",
       "      <td>5.381055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23933</td>\n",
       "      <td>[actualidad]</td>\n",
       "      <td>1</td>\n",
       "      <td>23933</td>\n",
       "      <td>13.493795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>135102</td>\n",
       "      <td>[mnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>135102</td>\n",
       "      <td>76.172595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numero_Noticias                                             Clases  \\\n",
       "0                 1  [Cómics, deportes, ebola, Documentales, Cuba, ...   \n",
       "1                 2  [Drones, Etimologia, museo, Encuestas, AEDE, B...   \n",
       "2                 3       [Ochenteando, Clicómics, Drogolegas, MADRID]   \n",
       "3                 4               [UHF, LGBT, Jurídicas, Лhcdss, Cine]   \n",
       "4                 5  [Palabros, Series, Sucesos, SysDevs, Japón, Cr...   \n",
       "5                 8                [gilipolleces, Cocíname, Preguntas]   \n",
       "6                 9                                             [dmnm]   \n",
       "7                10                       [idiomas, Música, softlibre]   \n",
       "8                11                                           [trenes]   \n",
       "9                12                                          [Fakeame]   \n",
       "10               13                                            [Bulos]   \n",
       "11               15                                         [Historia]   \n",
       "12               16                        [Abuso_Animal, Videojuegos]   \n",
       "13               21                                    [linux, BARCOS]   \n",
       "14               22                                           [OYOYOY]   \n",
       "15               27                                       [Visualdata]   \n",
       "16               30                                        [Artículos]   \n",
       "17               34                                     [escombrillos]   \n",
       "18               36                                       [Hemeroteca]   \n",
       "19               43                                          [Podemos]   \n",
       "20               55                                       [Pregúntame]   \n",
       "21               63                                       [TeRespondo]   \n",
       "22               77                                       [astronomia]   \n",
       "23              102                                             [emnm]   \n",
       "24              111                                          [ciencia]   \n",
       "25             3435                                             [ocio]   \n",
       "26             4415                                       [tecnología]   \n",
       "27             9544                                          [cultura]   \n",
       "28            23933                                       [actualidad]   \n",
       "29           135102                                              [mnm]   \n",
       "\n",
       "    Numero_Clases  Peso_Relativo  Peso_Total_Clase%  \n",
       "0              55             55           0.031010  \n",
       "1              12             24           0.013532  \n",
       "2               4             12           0.006766  \n",
       "3               5             20           0.011276  \n",
       "4               7             35           0.019734  \n",
       "5               3             24           0.013532  \n",
       "6               1              9           0.005074  \n",
       "7               3             30           0.016914  \n",
       "8               1             11           0.006202  \n",
       "9               1             12           0.006766  \n",
       "10              1             13           0.007330  \n",
       "11              1             15           0.008457  \n",
       "12              2             32           0.018042  \n",
       "13              2             42           0.023680  \n",
       "14              1             22           0.012404  \n",
       "15              1             27           0.015223  \n",
       "16              1             30           0.016914  \n",
       "17              1             34           0.019170  \n",
       "18              1             36           0.020297  \n",
       "19              1             43           0.024244  \n",
       "20              1             55           0.031010  \n",
       "21              1             63           0.035520  \n",
       "22              1             77           0.043414  \n",
       "23              1            102           0.057509  \n",
       "24              1            111           0.062584  \n",
       "25              1           3435           1.936706  \n",
       "26              1           4415           2.489245  \n",
       "27              1           9544           5.381055  \n",
       "28              1          23933          13.493795  \n",
       "29              1         135102          76.172595  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Asignacion:\n",
    "frecuencias2['Clases'] = clases_agrupa_nnc\n",
    "frecuencias2['Numero_Clases'] = numeros_clases_numero_texto\n",
    "frecuencias2['Peso_Relativo'] = frecuencias2['Numero_Noticias'] * frecuencias2['Numero_Clases']\n",
    "frecuencias2['Peso_Total_Clase%'] = frecuencias2['Peso_Relativo']/numero_textos_total * 100\n",
    "\n",
    "#Comprobacion:\n",
    "frecuencias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Comprobacion:\n",
    "print(len(clases_agrupa_nnc) == len(pd.unique(frecuencias['noticia'])))\n",
    "print(frecuencias2['Peso_Relativo'].sum() == numero_textos_total)\n",
    "print(frecuencias2['Peso_Total_Clase%'].sum() == 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Noticias</th>\n",
       "      <th>Clases</th>\n",
       "      <th>Numero_Clases</th>\n",
       "      <th>Peso_Relativo</th>\n",
       "      <th>Peso_Total_Clase%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>135102</td>\n",
       "      <td>[mnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>135102</td>\n",
       "      <td>76.172595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23933</td>\n",
       "      <td>[actualidad]</td>\n",
       "      <td>1</td>\n",
       "      <td>23933</td>\n",
       "      <td>13.493795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9544</td>\n",
       "      <td>[cultura]</td>\n",
       "      <td>1</td>\n",
       "      <td>9544</td>\n",
       "      <td>5.381055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4415</td>\n",
       "      <td>[tecnología]</td>\n",
       "      <td>1</td>\n",
       "      <td>4415</td>\n",
       "      <td>2.489245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3435</td>\n",
       "      <td>[ocio]</td>\n",
       "      <td>1</td>\n",
       "      <td>3435</td>\n",
       "      <td>1.936706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111</td>\n",
       "      <td>[ciencia]</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0.062584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>102</td>\n",
       "      <td>[emnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.057509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>77</td>\n",
       "      <td>[astronomia]</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.043414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63</td>\n",
       "      <td>[TeRespondo]</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.035520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>[Pregúntame]</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Cómics, deportes, ebola, Documentales, Cuba, ...</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>[Podemos]</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.024244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>[linux, BARCOS]</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.023680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "      <td>[Hemeroteca]</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.020297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Palabros, Series, Sucesos, SysDevs, Japón, Cr...</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>[escombrillos]</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.019170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>[Abuso_Animal, Videojuegos]</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.018042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>[Artículos]</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>[idiomas, Música, softlibre]</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>[Visualdata]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.015223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[gilipolleces, Cocíname, Preguntas]</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Drones, Etimologia, museo, Encuestas, AEDE, B...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>[OYOYOY]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[UHF, LGBT, Jurídicas, Лhcdss, Cine]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>[Historia]</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>[Bulos]</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>[Fakeame]</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Ochenteando, Clicómics, Drogolegas, MADRID]</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>[trenes]</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.006202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>[dmnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numero_Noticias                                             Clases  \\\n",
       "29           135102                                              [mnm]   \n",
       "28            23933                                       [actualidad]   \n",
       "27             9544                                          [cultura]   \n",
       "26             4415                                       [tecnología]   \n",
       "25             3435                                             [ocio]   \n",
       "24              111                                          [ciencia]   \n",
       "23              102                                             [emnm]   \n",
       "22               77                                       [astronomia]   \n",
       "21               63                                       [TeRespondo]   \n",
       "20               55                                       [Pregúntame]   \n",
       "0                 1  [Cómics, deportes, ebola, Documentales, Cuba, ...   \n",
       "19               43                                          [Podemos]   \n",
       "13               21                                    [linux, BARCOS]   \n",
       "18               36                                       [Hemeroteca]   \n",
       "4                 5  [Palabros, Series, Sucesos, SysDevs, Japón, Cr...   \n",
       "17               34                                     [escombrillos]   \n",
       "12               16                        [Abuso_Animal, Videojuegos]   \n",
       "16               30                                        [Artículos]   \n",
       "7                10                       [idiomas, Música, softlibre]   \n",
       "15               27                                       [Visualdata]   \n",
       "5                 8                [gilipolleces, Cocíname, Preguntas]   \n",
       "1                 2  [Drones, Etimologia, museo, Encuestas, AEDE, B...   \n",
       "14               22                                           [OYOYOY]   \n",
       "3                 4               [UHF, LGBT, Jurídicas, Лhcdss, Cine]   \n",
       "11               15                                         [Historia]   \n",
       "10               13                                            [Bulos]   \n",
       "9                12                                          [Fakeame]   \n",
       "2                 3       [Ochenteando, Clicómics, Drogolegas, MADRID]   \n",
       "8                11                                           [trenes]   \n",
       "6                 9                                             [dmnm]   \n",
       "\n",
       "    Numero_Clases  Peso_Relativo  Peso_Total_Clase%  \n",
       "29              1         135102          76.172595  \n",
       "28              1          23933          13.493795  \n",
       "27              1           9544           5.381055  \n",
       "26              1           4415           2.489245  \n",
       "25              1           3435           1.936706  \n",
       "24              1            111           0.062584  \n",
       "23              1            102           0.057509  \n",
       "22              1             77           0.043414  \n",
       "21              1             63           0.035520  \n",
       "20              1             55           0.031010  \n",
       "0              55             55           0.031010  \n",
       "19              1             43           0.024244  \n",
       "13              2             42           0.023680  \n",
       "18              1             36           0.020297  \n",
       "4               7             35           0.019734  \n",
       "17              1             34           0.019170  \n",
       "12              2             32           0.018042  \n",
       "16              1             30           0.016914  \n",
       "7               3             30           0.016914  \n",
       "15              1             27           0.015223  \n",
       "5               3             24           0.013532  \n",
       "1              12             24           0.013532  \n",
       "14              1             22           0.012404  \n",
       "3               5             20           0.011276  \n",
       "11              1             15           0.008457  \n",
       "10              1             13           0.007330  \n",
       "9               1             12           0.006766  \n",
       "2               4             12           0.006766  \n",
       "8               1             11           0.006202  \n",
       "6               1              9           0.005074  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ordenamos:\n",
    "frecuencias2 = frecuencias2.sort_values('Peso_Total_Clase%',ascending=False)\n",
    "frecuencias2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, unicamente las 3 primeras clases se llevan un 95,04% de los datos. Buscamos un conjunto de datos homogeneo para el cual hacer la prediccion por lo que vamos a descartar varias clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccion de entre un 0.01 hasta un 0.07 incluyendo ambos: \n",
    "condicion_si = (frecuencias2['Peso_Total_Clase%'] >= 0.0064) & (frecuencias2['Peso_Total_Clase%'] <= 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Noticias</th>\n",
       "      <th>Clases</th>\n",
       "      <th>Numero_Clases</th>\n",
       "      <th>Peso_Relativo</th>\n",
       "      <th>Peso_Total_Clase%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3435</td>\n",
       "      <td>[ocio]</td>\n",
       "      <td>1</td>\n",
       "      <td>3435</td>\n",
       "      <td>1.936706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111</td>\n",
       "      <td>[ciencia]</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0.062584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>102</td>\n",
       "      <td>[emnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.057509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>77</td>\n",
       "      <td>[astronomia]</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.043414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63</td>\n",
       "      <td>[TeRespondo]</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.035520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>[Pregúntame]</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Cómics, deportes, ebola, Documentales, Cuba, ...</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>[Podemos]</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.024244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>[linux, BARCOS]</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.023680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "      <td>[Hemeroteca]</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.020297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Palabros, Series, Sucesos, SysDevs, Japón, Cr...</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>[escombrillos]</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.019170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>[Abuso_Animal, Videojuegos]</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.018042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>[Artículos]</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>[idiomas, Música, softlibre]</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>[Visualdata]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.015223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[gilipolleces, Cocíname, Preguntas]</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Drones, Etimologia, museo, Encuestas, AEDE, B...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>[OYOYOY]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[UHF, LGBT, Jurídicas, Лhcdss, Cine]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>[Historia]</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.008457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>[Bulos]</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>[Fakeame]</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Ochenteando, Clicómics, Drogolegas, MADRID]</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numero_Noticias                                             Clases  \\\n",
       "25             3435                                             [ocio]   \n",
       "24              111                                          [ciencia]   \n",
       "23              102                                             [emnm]   \n",
       "22               77                                       [astronomia]   \n",
       "21               63                                       [TeRespondo]   \n",
       "20               55                                       [Pregúntame]   \n",
       "0                 1  [Cómics, deportes, ebola, Documentales, Cuba, ...   \n",
       "19               43                                          [Podemos]   \n",
       "13               21                                    [linux, BARCOS]   \n",
       "18               36                                       [Hemeroteca]   \n",
       "4                 5  [Palabros, Series, Sucesos, SysDevs, Japón, Cr...   \n",
       "17               34                                     [escombrillos]   \n",
       "12               16                        [Abuso_Animal, Videojuegos]   \n",
       "16               30                                        [Artículos]   \n",
       "7                10                       [idiomas, Música, softlibre]   \n",
       "15               27                                       [Visualdata]   \n",
       "5                 8                [gilipolleces, Cocíname, Preguntas]   \n",
       "1                 2  [Drones, Etimologia, museo, Encuestas, AEDE, B...   \n",
       "14               22                                           [OYOYOY]   \n",
       "3                 4               [UHF, LGBT, Jurídicas, Лhcdss, Cine]   \n",
       "11               15                                         [Historia]   \n",
       "10               13                                            [Bulos]   \n",
       "9                12                                          [Fakeame]   \n",
       "2                 3       [Ochenteando, Clicómics, Drogolegas, MADRID]   \n",
       "\n",
       "    Numero_Clases  Peso_Relativo  Peso_Total_Clase%  \n",
       "25              1           3435           1.936706  \n",
       "24              1            111           0.062584  \n",
       "23              1            102           0.057509  \n",
       "22              1             77           0.043414  \n",
       "21              1             63           0.035520  \n",
       "20              1             55           0.031010  \n",
       "0              55             55           0.031010  \n",
       "19              1             43           0.024244  \n",
       "13              2             42           0.023680  \n",
       "18              1             36           0.020297  \n",
       "4               7             35           0.019734  \n",
       "17              1             34           0.019170  \n",
       "12              2             32           0.018042  \n",
       "16              1             30           0.016914  \n",
       "7               3             30           0.016914  \n",
       "15              1             27           0.015223  \n",
       "5               3             24           0.013532  \n",
       "1              12             24           0.013532  \n",
       "14              1             22           0.012404  \n",
       "3               5             20           0.011276  \n",
       "11              1             15           0.008457  \n",
       "10              1             13           0.007330  \n",
       "9               1             12           0.006766  \n",
       "2               4             12           0.006766  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resumen datos clasificacion:\n",
    "frecuencias3 =  frecuencias2[condicion_si]\n",
    "frecuencias3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disponibles: \n",
      "\n",
      "['ocio', 'ciencia', 'emnm', 'astronomia', 'TeRespondo', 'Pregúntame', 'Cómics', 'deportes', 'ebola', 'Documentales', 'Cuba', 'aviones', 'gatos', 'INTERNAC', 'mexico', 'CiFi', 'Cantabria', 'mascotas', 'medicina', 'Biologia', 'movilidad', 'netsec', 'opinion', 'retrocomp', 'smartphone', 'Autorrelatos', 'Animales', 'veganismo', 'autonomos', 'Economía', 'android', 'Filosofía', 'KKKantiPDMS', 'Hazlotumismo', 'Libros', 'MAmbiente', 'Galicia', 'Natación', 'Neurociencia', 'GNU_LINUX', 'OrienteMedio', 'PREVENCIÓN', 'Fotomundo', 'Poesia', 'Firefox', 'Psicópatas', 'alas', 'QUEJAS', 'RPDC', 'RaspberryPi', 'Rusia', 'SEXOLOGÍA', 'STARWARS', 'Feminismo', 'Eurovision', 'Entrevistas', 'Ubuntu', 'EleccionesE', 'IMGUR', 'ELBAÚL', 'ACME', 'Podemos', 'linux', 'BARCOS', 'Hemeroteca', 'Palabros', 'Series', 'Sucesos', 'SysDevs', 'Japón', 'Crianza', 'BUAMBUSUB', 'escombrillos', 'Abuso_Animal', 'Videojuegos', 'Artículos', 'idiomas', 'Música', 'softlibre', 'Visualdata', 'gilipolleces', 'Cocíname', 'Preguntas', 'Drones', 'Etimologia', 'museo', 'Encuestas', 'AEDE', 'Barcelona', 'RebeliónMnm', 'procescatalà', 'NoMundoToday', 'Venezuela', 'salud', 'Alimentación', 'OYOYOY', 'UHF', 'LGBT', 'Jurídicas', 'Лhcdss', 'Cine', 'Historia', 'Bulos', 'Fakeame', 'Ochenteando', 'Clicómics', 'Drogolegas', 'MADRID']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "No disponibles: \n",
      "\n",
      "['cultura', 'tecnología', 'actualidad', 'mnm', 'trenes', 'dmnm']\n"
     ]
    }
   ],
   "source": [
    "#Cogemos la lista con las clases disponibles.\n",
    "disponibles = [] #Las clases que clasificamos \n",
    "\n",
    "for i in frecuencias3['Clases']:\n",
    "    disponibles.extend(i)\n",
    "\n",
    "print('Disponibles: \\n')\n",
    "print(disponibles)\n",
    "\n",
    "print('\\n'*4)\n",
    "\n",
    "no_disponibles = []#Las clases que eliminamos \n",
    "for i in clases:\n",
    "    if i not in disponibles:\n",
    "        no_disponibles.append(i)\n",
    "        \n",
    "print('No disponibles: \\n')\n",
    "print(no_disponibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos los indices de las clases disponibles:\n",
    "indices_disponibles = frecuencias3.index.values #Filas clases disponibles\n",
    "# print(indices_disponibles)\n",
    "\n",
    "indices_no_disponibles = []#Filas clases no disponibles \n",
    "for i in frecuencias2.index.values:\n",
    "    if i not in indices_disponibles:\n",
    "        indices_no_disponibles.append(i)\n",
    "    \n",
    "# print(indices_no_disponibles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Noticias</th>\n",
       "      <th>Clases</th>\n",
       "      <th>Numero_Clases</th>\n",
       "      <th>Peso_Relativo</th>\n",
       "      <th>Peso_Total_Clase%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>135102</td>\n",
       "      <td>[mnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>135102</td>\n",
       "      <td>76.172595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23933</td>\n",
       "      <td>[actualidad]</td>\n",
       "      <td>1</td>\n",
       "      <td>23933</td>\n",
       "      <td>13.493795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9544</td>\n",
       "      <td>[cultura]</td>\n",
       "      <td>1</td>\n",
       "      <td>9544</td>\n",
       "      <td>5.381055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4415</td>\n",
       "      <td>[tecnología]</td>\n",
       "      <td>1</td>\n",
       "      <td>4415</td>\n",
       "      <td>2.489245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>[trenes]</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.006202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>[dmnm]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Numero_Noticias        Clases  Numero_Clases  Peso_Relativo  \\\n",
       "29           135102         [mnm]              1         135102   \n",
       "28            23933  [actualidad]              1          23933   \n",
       "27             9544     [cultura]              1           9544   \n",
       "26             4415  [tecnología]              1           4415   \n",
       "8                11      [trenes]              1             11   \n",
       "6                 9        [dmnm]              1              9   \n",
       "\n",
       "    Peso_Total_Clase%  \n",
       "29          76.172595  \n",
       "28          13.493795  \n",
       "27           5.381055  \n",
       "26           2.489245  \n",
       "8            0.006202  \n",
       "6            0.005074  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resumen datos no clasificacion:\n",
    "frecuencias4 = frecuencias2.loc[indices_no_disponibles, ]\n",
    "frecuencias4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>sub</th>\n",
       "      <th>extracto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Lárgame un cilindrín, fotero”</td>\n",
       "      <td>ocio</td>\n",
       "      <td>‘La gran superproducción‘ es, sin ningún géner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>El capitalismo japonés: librándonos de mirada...</td>\n",
       "      <td>Japón</td>\n",
       "      <td>La Exposición Internacional de Osaka de 1970 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Republicanos monárquicos</td>\n",
       "      <td>escombrillos</td>\n",
       "      <td>En una reciente opinión  publicada en el sub de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Buckley: (bendito) apellido maldito</td>\n",
       "      <td>ocio</td>\n",
       "      <td>Una de las lecciones más valiosas que puede ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Estoy cansado de los magufos manipuladores</td>\n",
       "      <td>BUAMBUSUB</td>\n",
       "      <td>Hay días en que las redes sociales le quitan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69737</th>\n",
       "      <td>YouPorn: Las estadísticas del porno gratis</td>\n",
       "      <td>emnm</td>\n",
       "      <td>La presencia del contenido XXX en la Web está ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70237</th>\n",
       "      <td>Multan con 50.000 euros a un banco por inclui...</td>\n",
       "      <td>emnm</td>\n",
       "      <td>La Agencia Española de Protección de Datos aca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70385</th>\n",
       "      <td>Expertos escolares abogan por separar a los n...</td>\n",
       "      <td>emnm</td>\n",
       "      <td>¿Qué pensaría si su hijo pequeño regresa del c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70834</th>\n",
       "      <td>Guía para usar Calibre, administra tu bibliot...</td>\n",
       "      <td>emnm</td>\n",
       "      <td>«Lo primero que tenemos que saber es que Calib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73269</th>\n",
       "      <td>Corto: 85.12.30</td>\n",
       "      <td>emnm</td>\n",
       "      <td>Un corto de Manuel Bartual.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4349 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 noticia           sub  \\\n",
       "2                        “Lárgame un cilindrín, fotero”           ocio   \n",
       "29      El capitalismo japonés: librándonos de mirada...         Japón   \n",
       "30                              Republicanos monárquicos  escombrillos   \n",
       "42                  Buckley: (bendito) apellido maldito           ocio   \n",
       "56            Estoy cansado de los magufos manipuladores     BUAMBUSUB   \n",
       "...                                                  ...           ...   \n",
       "69737        YouPorn: Las estadísticas del porno gratis           emnm   \n",
       "70237   Multan con 50.000 euros a un banco por inclui...          emnm   \n",
       "70385   Expertos escolares abogan por separar a los n...          emnm   \n",
       "70834   Guía para usar Calibre, administra tu bibliot...          emnm   \n",
       "73269                                   Corto: 85.12.30           emnm   \n",
       "\n",
       "                                                extracto  \n",
       "2      ‘La gran superproducción‘ es, sin ningún géner...  \n",
       "29     La Exposición Internacional de Osaka de 1970 s...  \n",
       "30      En una reciente opinión  publicada en el sub de   \n",
       "42     Una de las lecciones más valiosas que puede ap...  \n",
       "56      Hay días en que las redes sociales le quitan ...  \n",
       "...                                                  ...  \n",
       "69737  La presencia del contenido XXX en la Web está ...  \n",
       "70237  La Agencia Española de Protección de Datos aca...  \n",
       "70385  ¿Qué pensaría si su hijo pequeño regresa del c...  \n",
       "70834  «Lo primero que tenemos que saber es que Calib...  \n",
       "73269                       Un corto de Manuel Bartual.   \n",
       "\n",
       "[4349 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seleccionamos\n",
    "condicion = (df2['sub']!= 'mnm') & (df2['sub']!= 'actualidad') & (df2['sub']!= 'cultura') & (df2['sub']!= 'tecnología') & (df2['sub']!= 'trenes') & (df2['sub']!= 'dmnm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# condicion = (df2['sub']!= 'mnm')\n",
    "df3 = df2[condicion]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177363, 3)\n",
      "(4349, 3)\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos cuantas fila con na hemos eliminado\n",
    "print(df2.shape)\n",
    "print(df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(' Ruptura inesperada de un iceberg gigante desprendido del mayor glaciar antártico vista por satélite (ING) ',\n",
       " 'cultura',\n",
       " 'Una animación del iceberg gigante que nació del Glaciar Pine Island en la Antártida Occidental hace poco más de dos meses muestra una ruptura inesperada vista por satélite. -Lo que estamos presenciando en Pine Island es preocupante. Ahora estamos viendo cambios en el comportamiento de la plataforma de hielo, cuando durante 68 años vimos un patrón de avance y retroceso que resultó en el nacimiento de un solo iceberg grande- dice Robert Larter, geofísico marino de British Antarctic Survey. En español: ')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos el objeto generador\n",
    "noticia = next(parse('./meneame.csv/data.csv'))\n",
    "noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>noticia</th>\n",
       "      <th>meneos</th>\n",
       "      <th>clicks</th>\n",
       "      <th>comentarios</th>\n",
       "      <th>votos_positivos</th>\n",
       "      <th>votos_anonimos</th>\n",
       "      <th>votos_negativos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2869055</td>\n",
       "      <td>Ruptura inesperada de un iceberg gigante desp...</td>\n",
       "      <td>73</td>\n",
       "      <td>1057</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2869761</td>\n",
       "      <td>El MIT logra hacer escáneres 3D baratos 1,000...</td>\n",
       "      <td>73</td>\n",
       "      <td>772</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2869841</td>\n",
       "      <td>“Lárgame un cilindrín, fotero”</td>\n",
       "      <td>89</td>\n",
       "      <td>1608</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2869859</td>\n",
       "      <td>El Tribunal Supremo deja en prisión a Junquer...</td>\n",
       "      <td>171</td>\n",
       "      <td>889</td>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2869823</td>\n",
       "      <td>La Fiscalía pide imputar a Aguirre y Gallardó...</td>\n",
       "      <td>354</td>\n",
       "      <td>353</td>\n",
       "      <td>39</td>\n",
       "      <td>144</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177504</th>\n",
       "      <td>6</td>\n",
       "      <td>Instalar Linux en iPod Mini | GPL Tarragona</td>\n",
       "      <td>29</td>\n",
       "      <td></td>\n",
       "      <td>sin</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177505</th>\n",
       "      <td>4</td>\n",
       "      <td>Entrevista de El Mundo a Jose Antonio Marina</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>sin</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177506</th>\n",
       "      <td>3</td>\n",
       "      <td>Prova xfce 4.2.3!</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>sin</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177507</th>\n",
       "      <td>2</td>\n",
       "      <td>Los 84 errores de noxtrum</td>\n",
       "      <td>61</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177508</th>\n",
       "      <td>1</td>\n",
       "      <td>Ésta es la primera noticia meneada</td>\n",
       "      <td>246</td>\n",
       "      <td></td>\n",
       "      <td>21</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177509 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index                                            noticia  meneos  \\\n",
       "0       2869055   Ruptura inesperada de un iceberg gigante desp...      73   \n",
       "1       2869761   El MIT logra hacer escáneres 3D baratos 1,000...      73   \n",
       "2       2869841                    “Lárgame un cilindrín, fotero”       89   \n",
       "3       2869859   El Tribunal Supremo deja en prisión a Junquer...     171   \n",
       "4       2869823   La Fiscalía pide imputar a Aguirre y Gallardó...     354   \n",
       "...         ...                                                ...     ...   \n",
       "177504        6       Instalar Linux en iPod Mini | GPL Tarragona       29   \n",
       "177505        4      Entrevista de El Mundo a Jose Antonio Marina       18   \n",
       "177506        3                                 Prova xfce 4.2.3!       34   \n",
       "177507        2                         Los 84 errores de noxtrum       61   \n",
       "177508        1                Ésta es la primera noticia meneada      246   \n",
       "\n",
       "       clicks comentarios  votos_positivos  votos_anonimos  votos_negativos  \n",
       "0        1057          10               55              18                2  \n",
       "1         772          17               43              30                1  \n",
       "2        1608          34               53              36                5  \n",
       "3         889          90               98              73                1  \n",
       "4         353          39              144             210                0  \n",
       "...       ...         ...              ...             ...              ...  \n",
       "177504                sin               29               0                0  \n",
       "177505                sin               18               0                0  \n",
       "177506                sin               34               0                0  \n",
       "177507                  5               61               0                0  \n",
       "177508                 21              246               0                0  \n",
       "\n",
       "[177509 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisis exploratorio a partir de df. Seleccionamos las columnas: noticia, meneos, clicks,\n",
    "#comentarios, votos_positivos, votos_negativos, votos_anonimos.\n",
    "\n",
    "exploratorio = df.loc[:,['index' ,'noticia', 'meneos', 'clicks', 'comentarios',\n",
    "       'votos_positivos', 'votos_anonimos', 'votos_negativos']]\n",
    "exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PRE-PROCESADO\n",
    "Realizaremos el siguiente procesado:\n",
    "- Separar el texto en *tokens*\n",
    "- Eliminar los *tokens* de tipo *stop-word*, signos de puntuación, signos especiales o espacios\n",
    "- Lematizar el texto\n",
    "- Introducimos un espacio después de determinados signos de puntuación (\".\", \"?\", \"%\") para que el tokenizado sea correcto\n",
    "- Filtramos los *tokens* con una longitud de 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_lg\") #Mejor modelo optimizado para la CPU\n",
    "\n",
    "#definimos función de normalizado\n",
    "def normaliza(texto):\n",
    "    texto = re.sub(r\"(\\.)|(\\?)|(\\%)\", r\"\\1 |\\2 |\\3 \", texto) #añadimos un espacio después de \".\" y \"?\"\n",
    "    doc = nlp(texto)\n",
    "    tokens = [t for t in doc if\n",
    "                        len(t.text)>1 and\n",
    "                       not t.is_stop and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]#filtramos los tokens que nos interesan\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        palabras.append(t.lemma_) #añadimos lema\n",
    "    salida = ' '.join(palabras)#junta todos los tokens en un string\n",
    "    \n",
    "    return salida\n",
    "\n",
    "#funcion para quitar acentos y caracteres no ASCII:\n",
    "\n",
    "def remove_accents(input_str):     \n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)     \n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')     \n",
    "    return only_ascii.decode(\"utf-8\", 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ruptura inesperada de un iceberg gigante desprendido del mayor glaciar antártico vista por satélite (ING) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ruptura inesperado iceberg gigante desprender glaciar antártico vestir satélite ING'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos que funciona con el elemento 0 de noticia (\"noticia\")\n",
    "print(noticia[0])\n",
    "normaliza(noticia[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizamos todo el texto de ambas columnas\n",
    "#noticia1 = [normaliza(i[0]) for i in parse('./meneame.csv/data.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una animación del iceberg gigante que nació del Glaciar Pine Island en la Antártida Occidental hace poco más de dos meses muestra una ruptura inesperada vista por satélite. -Lo que estamos presenciando en Pine Island es preocupante. Ahora estamos viendo cambios en el comportamiento de la plataforma de hielo, cuando durante 68 años vimos un patrón de avance y retroceso que resultó en el nacimiento de un solo iceberg grande- dice Robert Larter, geofísico marino de British Antarctic Survey. En español: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'animación iceberg gigante nacer Glaciar Pine Island Antártida Occidental mesar mostrar ruptura inesperado vestir satélite -Lo presenciar Pine Island preocupante ver cambio comportamiento plataforma helar 68 año ver patrón avanzar retroceso resultar nacimiento iceberg grande- Robert Larter geofísico marinar British Antarctic Survey español'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos que funciona con el elemento 2 de noticia (\"extracto\")\n",
    "print(noticia[2])\n",
    "normaliza(noticia[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizamos todo el texto de ambas columnas\n",
    "#extracto1 = [normaliza(i[2]) for i in parse('./meneame.csv/data.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de corpus y labels \n",
    "corpus = df3['extracto'].tolist() + df3['noticia'].tolist()\n",
    "labels_posibles = pd.unique(df2['sub']).tolist()\n",
    "labels = df3['sub'].tolist() + df3['sub'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño  TOTAL: 8698\n",
      "Tamaño de clase TOTAL: 8698\n"
     ]
    }
   ],
   "source": [
    "#Vemos cuantas observaciones en total tenemos.\n",
    "print(f'\\nTamaño  TOTAL: {len(corpus)}')\n",
    "print(f'Tamaño de clase TOTAL: {len(labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos 5000 muestras del cojunto de datos total\n",
    "corpus_sm, labels_sm = resample(corpus, labels, n_samples=5000, replace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separacion del conjunto de datos P5\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(corpus_sm, labels_sm, test_size = 0.30, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de TRAIN: 3500\n",
      "Tamaño de clase TRAIN: 3500\n",
      "\n",
      "Tamaño de TEST: 1500\n",
      "Tamaño de clase TEST: 1500\n"
     ]
    }
   ],
   "source": [
    "# COMPLETAR\n",
    "print(f'\\nTamaño de TRAIN: {len(train_corpus)}')\n",
    "print(f'Tamaño de clase TRAIN: {len(train_labels)}')\n",
    "\n",
    "print(f'\\nTamaño de TEST: {len(test_corpus)}')\n",
    "print(f'Tamaño de clase TEST: {len(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los extractos y los guardamos como una lista en lugar de generator porque \n",
    "#lo tenemos que múltiples veces y no queremos tener que normalizar todo el corpus cada vez.\n",
    "norm_train_corpus = list(map(normaliza, train_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test_corpus = list(map(normaliza, test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EXTRACCION DE CARACTERISTICAS\n",
    "Instanciamos los vectorizadores para obtener las características BoW y TF-IDF.  \n",
    "Usamos el parámetro max_df=0.9 para eliminar los stop-words como las palabras que aparecen al menos en el 90% de los documentos y el parámetro min_df=0.01 para eliminar las palabras que no aparecen al menos en un 1% de los documentos.\\\n",
    "\n",
    "Usamos el modelo `TfidfTransformer` para calcular la matriz TF-IDF a partir del BoW y no tener que repetir todo el entrenamiento.\n",
    "\n",
    "Para calcular los modelos basados en WV usamos el modelo gloVe pre-entrenado en `spaCy`. Calculamos dos modelos basados en word-vectors:  \n",
    "* El vector promedio de los WV de todos los tokens con el mismo peso para todas las palabras.  \n",
    "* Ponderando el WV de cada palabra por el término de frecuencia inversa de documento (IDF).  \n",
    "\n",
    "Definimos las funciones para calcular estas dos matrices de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW\n",
    "bow_vectorizer = CountVectorizer(min_df=0.01, max_df=0.9)\n",
    "\n",
    "#Tf-idf\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "\n",
    "#Funciones de WV.\n",
    "def averaged_word_vectorizer(corpus):\n",
    "    '''Aplica la función de cálculo del WE promedio a todos los\n",
    "    documentos del corpus (cada doc es una lista de tokens)'''\n",
    "    features = [nlp(doc).vector\n",
    "                    for doc in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "def tfidf_wtd_avg_word_vectors(doc, word_tfidf_map):\n",
    "    '''Aplica la función de cálculo del WE ponderado por TF-IDF\n",
    "    a un documento (como lista de tokens)'''\n",
    "    tokens = doc.split()\n",
    "\n",
    "    feature_vector = np.zeros((nlp.vocab.vectors_length,),dtype=\"float64\")\n",
    "    wts = 0.      \n",
    "    for word in tokens:\n",
    "        if nlp.vocab[word].has_vector and word_tfidf_map.get(word, 0): #sólo considera palabras conocidas\n",
    "            weighted_word_vector = word_tfidf_map[word] * nlp.vocab[word].vector\n",
    "            wts = wts + 1\n",
    "            feature_vector = np.add(feature_vector, weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector = np.divide(feature_vector, wts)\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus, word_tfidf_map):\n",
    "    '''Aplica la función de cálculo del WE ponderado por TF-IDF a todos los\n",
    "    documentos del corpus (cada doc es una lista de tokens)'''                                       \n",
    "    features = [tfidf_wtd_avg_word_vectors(doc, word_tfidf_map)\n",
    "                    for doc in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# características bag of words\n",
    "bow_train_features = bow_vectorizer.fit_transform(norm_train_corpus)  \n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus) \n",
    "\n",
    "# características tfidf (a partir del BoW)\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(bow_train_features)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(bow_test_features)    \n",
    "\n",
    "# características averaged word vector\n",
    "avg_wv_train_features = averaged_word_vectorizer(norm_train_corpus)                \n",
    "avg_wv_test_features = averaged_word_vectorizer(norm_test_corpus)      \n",
    "\n",
    "# características tfidf weighted averaged word vector\n",
    "word_tfidf_map = {key:value for (key, value) in zip(bow_vectorizer.get_feature_names(), tfidf_vectorizer.idf_)}\n",
    "\n",
    "tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(norm_train_corpus, word_tfidf_map)\n",
    "\n",
    "tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizer(norm_test_corpus, word_tfidf_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 137)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 137)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_wv_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_wv_train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLASIFICADOR\n",
    "Aplicamos distintos clasificadores a cada modelo para ver cuál funciona mejor con nuestros datos. Primero definimos unas funciones para entrenar y medir el rendimiento de los clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Calculamos distintas métricas sobre el\n",
    "    rendimiento del modelo. Devuelve un diccionario\n",
    "    con los parámetros medidos\"\"\"\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        3),\n",
    "        'Precision': np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3),\n",
    "    'Recall': np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3),\n",
    "    'F1 Score': np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3)}\n",
    "                        \n",
    "\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    \"\"\"Función que entrena un modelo de clasificación sobre\n",
    "    un conjunto de entrenamiento, lo aplica sobre un conjunto\n",
    "    de test y devuelve la predicción sobre el conjunto de test\n",
    "    y las métricas de rendimiento\"\"\"\n",
    "    # genera modelo    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predice usando el modelo sobre test\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evalúa rendimiento de la predicción   \n",
    "    metricas = get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions, metricas     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar sobre el conjunto de train y evaluamos en el conjunto de test. Guardamos métricas en una lista y resultados en otra para mostrar resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "modelLR = LogisticRegression(solver='liblinear')\n",
    "modelNB = GaussianNB()\n",
    "modelSVM = SGDClassifier(loss='hinge', max_iter=1000)\n",
    "modelRBFSVM = SVC(gamma='scale', C=2)\n",
    "\n",
    "modelos = [('Logistic Regression', modelLR),\n",
    "           ('Naive Bayes', modelNB),\n",
    "           ('Linear SVM', modelSVM),\n",
    "           ('Gauss kernel SVM', modelRBFSVM)]\n",
    "\n",
    "metricas = []\n",
    "resultados = []\n",
    "\n",
    "# Modelos con características BoW\n",
    "bow_train_features_ = bow_train_features.toarray()\n",
    "bow_test_features_ = bow_test_features.toarray()\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=bow_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} BoW'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "    \n",
    "# Modelos con características TF-IDF\n",
    "tfidf_train_features_ = tfidf_train_features.toarray()\n",
    "tfidf_test_features_ = tfidf_test_features.toarray()\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=tfidf_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} tfidf'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "\n",
    "# Modelos con características averaged word vectors\n",
    "avg_wv_train_features_ = avg_wv_train_features\n",
    "avg_wv_test_features_ = avg_wv_test_features\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=avg_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} averaged'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "\n",
    "# Modelos con características tfidf weighted averaged word vectors\n",
    "tfidf_wv_train_features_ = tfidf_wv_train_features\n",
    "tfidf_wv_test_features_ = tfidf_wv_test_features\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=tfidf_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} tfidf wv'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviertimos la lista de métricas en un DataFrame para observar sus valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.724</td>\n",
       "      <td>Logistic Regression BoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.343</td>\n",
       "      <td>Naive Bayes BoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.727</td>\n",
       "      <td>Linear SVM BoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.725</td>\n",
       "      <td>Gauss kernel SVM BoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.723</td>\n",
       "      <td>Logistic Regression tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.234</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.344</td>\n",
       "      <td>Naive Bayes tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.725</td>\n",
       "      <td>Linear SVM tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.726</td>\n",
       "      <td>Gauss kernel SVM tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.759</td>\n",
       "      <td>Logistic Regression averaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.263</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.346</td>\n",
       "      <td>Naive Bayes averaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.743</td>\n",
       "      <td>Linear SVM averaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.765</td>\n",
       "      <td>Gauss kernel SVM averaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Logistic Regression tfidf wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.155</td>\n",
       "      <td>Naive Bayes tfidf wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.662</td>\n",
       "      <td>Linear SVM tfidf wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Gauss kernel SVM tfidf wv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Precision  Recall  F1 Score                        modelo\n",
       "0      0.805      0.663   0.805     0.724       Logistic Regression BoW\n",
       "1      0.233      0.686   0.233     0.343               Naive Bayes BoW\n",
       "2      0.807      0.665   0.807     0.727                Linear SVM BoW\n",
       "3      0.808      0.668   0.808     0.725          Gauss kernel SVM BoW\n",
       "4      0.807      0.663   0.807     0.723     Logistic Regression tfidf\n",
       "5      0.234      0.687   0.234     0.344             Naive Bayes tfidf\n",
       "6      0.808      0.663   0.808     0.725              Linear SVM tfidf\n",
       "7      0.805      0.687   0.805     0.726        Gauss kernel SVM tfidf\n",
       "8      0.797      0.733   0.797     0.759  Logistic Regression averaged\n",
       "9      0.263      0.731   0.263     0.346          Naive Bayes averaged\n",
       "10     0.765      0.726   0.765     0.743           Linear SVM averaged\n",
       "11     0.830      0.729   0.830     0.765     Gauss kernel SVM averaged\n",
       "12     0.787      0.641   0.787     0.706  Logistic Regression tfidf wv\n",
       "13     0.097      0.656   0.097     0.155          Naive Bayes tfidf wv\n",
       "14     0.669      0.657   0.669     0.662           Linear SVM tfidf wv\n",
       "15     0.799      0.642   0.799     0.712     Gauss kernel SVM tfidf wv"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas = pd.DataFrame(metricas)\n",
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las métricas por `accuracy` y muestra el mejor resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.765</td>\n",
       "      <td>Gauss kernel SVM averaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Precision  Recall  F1 Score                     modelo\n",
       "11      0.83      0.729    0.83     0.765  Gauss kernel SVM averaged"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas = metricas.sort_values('Accuracy',ascending=False)\n",
    "metricas.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoramos el `accuracy` a partir del juego de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#Funcion de gamma\n",
    "gamma = ['scale', 'auto']\n",
    "\n",
    "metricas = []\n",
    "resultados = []\n",
    "\n",
    "\n",
    "for i in gamma:\n",
    "    modelRBFSVM = SVC(gamma=i, C=2)\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=modelRBFSVM,\n",
    "                                           train_features=avg_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{i} – Gauss kernel SVM averaged'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviertimos la lista de métricas en un DataFrame para observar sus valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.765</td>\n",
       "      <td>scale – Gauss kernel SVM averaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.758</td>\n",
       "      <td>auto – Gauss kernel SVM averaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall  F1 Score                             modelo\n",
       "0     0.830      0.729   0.830     0.765  scale – Gauss kernel SVM averaged\n",
       "1     0.825      0.724   0.825     0.758   auto – Gauss kernel SVM averaged"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas = pd.DataFrame(metricas)\n",
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las métricas por `accuracy` y muestra el mejor resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.765</td>\n",
       "      <td>scale – Gauss kernel SVM averaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Recall  F1 Score                             modelo\n",
       "0      0.83      0.729    0.83     0.765  scale – Gauss kernel SVM averaged"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas = metricas.sort_values('Accuracy',ascending=False)\n",
    "metricas.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el conjunto total de muestras (`corpus` y `labels`) en entrenamiento y test (30%) y entrenamos el mejor modelo obtenido, para ver si se mejoran los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEJOR MODELO\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(corpus, labels, test_size = 0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos\n",
    "norm_train_corpus = list(map(normaliza, train_corpus))\n",
    "norm_test_corpus = list(map(normaliza, test_corpus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características averaged word vector\n",
    "avg_wv_train_features = averaged_word_vectorizer(norm_train_corpus)                \n",
    "avg_wv_test_features = averaged_word_vectorizer(norm_test_corpus)      \n",
    "avg_wv_train_features_ = avg_wv_train_features\n",
    "avg_wv_test_features_ = avg_wv_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos con características\n",
    "modelRBFSVM = SVC(gamma='scale', C=2)\n",
    "prediccion, metrica = train_predict_evaluate_model(classifier=modelRBFSVM,\n",
    "                                           train_features=avg_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Gauss kernel SVM averaged con gamma scale: \n",
      "-  Accuracy :  0.828\n",
      "-  Precision :  0.727\n",
      "-  Recall :  0.828\n",
      "-  F1 Score :  0.763\n",
      "\n",
      "Predicciones:\n",
      "['ocio' 'ocio' 'ocio' ... 'ocio' 'ocio' 'ocio']\n"
     ]
    }
   ],
   "source": [
    "print('Modelo Gauss kernel SVM averaged con gamma scale: ')\n",
    "for i in metrica:\n",
    "    print('- ',i, ': ', metrica[i])\n",
    "\n",
    "print('\\nPredicciones:')\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ocio', 'astronomia', 'ciencia', 'TeRespondo', 'linux',\n",
       "       'Pregúntame', 'emnm', 'Palabros', 'Jurídicas', 'BARCOS'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(prediccion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clasificacion_3915",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a821d265b19b8e474c372894184ad502aefb1f7882947607cd0ea5f074b097d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
