{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 2: Clasificador de noticias\n",
    "\n",
    "### Nombres:\n",
    "Introduce en esta celda los nombres de los dos integrantes del grupo:\n",
    "- *Alumno 1:* DANIEL CARMONA PEDRAJAS\n",
    "- *Alumno 2:* JOEL PARDO FERRERA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo: Implementar un clasificador usando el conjunto de datos recopilado de varias fuentes de internet como:\n",
    "\n",
    "- Google News que toma noticias de varios repositorios dedicados a la información\n",
    "- Periódicos:\n",
    "    - El País\n",
    "    - ABC\n",
    "    - El Confidencial\n",
    "    - 20minutos\n",
    "    - El Diario\n",
    "\n",
    "Este repositorio incluye tanto las noticias en formato '.txt' donde se almacenan los cuerpos de noticia y sus correspondientes títulos, como un '.csv' donde se contiene un registro de todas las noticias donde se refleja el número de noticias, la clase a la que pertenece (deportes, salud, ciencia y politica), el número de noticia dentro de la clase correspondiente, el título de noticia, la ruta donde está almacenada esa noticia, y por último la URL de donde se ha sacado la noticia. \n",
    "\n",
    "La fechas tanto de publicación como de obtención e datos se ubican en Noviembre de 2022. \n",
    "\n",
    "La clase a predecir es el tipo de noticia (columna 'category' de la base de datos), a partir de los archivos '.txt'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÓN DE LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git config --global user.email \"jpardo0824@gmail.com\"\n",
    "# git config --global user.name \"JPardo08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas\n",
    "# !pip3 install spacy\n",
    "# !pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import unicodedata\n",
    "import os\n",
    "#from spellchecker import SpellChecker \n",
    "#from textblob import TextBlob \n",
    "#import contractions\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CARGA DE DATOS\n",
    "Cargamos los datos en dos formatos:\n",
    "* DataFrame de pandas\n",
    "* Generador\n",
    "\n",
    "Para cargar los datos utilizamos la librería pandas. \n",
    "La funcion implementada recibe la ruta del archivo .csv que queramos cargar y devuelve los textos en una variable generador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"..\" ## CAMBIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_txts(dataframe):\n",
    "    \"\"\" \n",
    "    Función para coger los documentos '.txt' de las noticias\n",
    "    \"\"\"\n",
    "    paths = dataframe[\"path\"].tolist()\n",
    "    clases = dataframe[\"category\"].unique().tolist()\n",
    "\n",
    "    documentos = []\n",
    "\n",
    "    for p in paths:\n",
    "        t = p.replace(\".\", ruta, 1) \n",
    "        s = t.replace(\"/\", \"//\")\n",
    "        print(s)\n",
    "\n",
    "        with open(s, \"r\", encoding=\"latin-1\", errors='ignore') as f:\n",
    "            lineas = f.readlines()\n",
    "            txt1 = ''.join(lineas)\n",
    "            documentos.append(txt1)\n",
    "            \n",
    "    return clases, documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//Datos//urls1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_18128\\2303741000.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  noticias_dataframe = pd.read_csv(path_urls_dataframe,',')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>category</th>\n",
       "      <th>n_doc</th>\n",
       "      <th>title</th>\n",
       "      <th>path</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "      <td>Memphis y Dumfries certifican que el 'soccer' ...</td>\n",
       "      <td>./Datos/Raw_data/sports/1.txt</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>2</td>\n",
       "      <td>Con el dinero no basta en el fútbol - AS</td>\n",
       "      <td>./Datos/Raw_data/sports/2.txt</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sports</td>\n",
       "      <td>3</td>\n",
       "      <td>El fútbol es un cuento - La Voz de Galicia</td>\n",
       "      <td>./Datos/Raw_data/sports/3.txt</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>4</td>\n",
       "      <td>Cavani y Giménez serán sancionados pero no con...</td>\n",
       "      <td>./Datos/Raw_data/sports/4.txt</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sports</td>\n",
       "      <td>5</td>\n",
       "      <td>Suspendido por una tangana a puñetazos el Alme...</td>\n",
       "      <td>./Datos/Raw_data/sports/5.txt</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index category  n_doc                                              title  \\\n",
       "0      0   sports      1  Memphis y Dumfries certifican que el 'soccer' ...   \n",
       "1      1   sports      2          Con el dinero no basta en el fútbol - AS    \n",
       "2      2   sports      3         El fútbol es un cuento - La Voz de Galicia   \n",
       "3      3   sports      4  Cavani y Giménez serán sancionados pero no con...   \n",
       "4      4   sports      5  Suspendido por una tangana a puñetazos el Alme...   \n",
       "\n",
       "                            path  \\\n",
       "0  ./Datos/Raw_data/sports/1.txt   \n",
       "1  ./Datos/Raw_data/sports/2.txt   \n",
       "2  ./Datos/Raw_data/sports/3.txt   \n",
       "3  ./Datos/Raw_data/sports/4.txt   \n",
       "4  ./Datos/Raw_data/sports/5.txt   \n",
       "\n",
       "                                                link  \n",
       "0  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "1  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "2  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "3  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "4  https://news.google.com/__i/rss/rd/articles/CB...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_dataframe = ruta + \"/Datos/urls1.csv\"\n",
    "path_urls_dataframe = urls_dataframe.replace(\"/\", \"//\")\n",
    "print(path_urls_dataframe)\n",
    "\n",
    "# df_gen = parse(r'/Users/joelpardo/Desktop/TextClassification/Datos/urls1.csv')\n",
    "\n",
    "\n",
    "\n",
    "noticias_dataframe = pd.read_csv(path_urls_dataframe,',')\n",
    "\n",
    "#Visualizamos los datos\n",
    "noticias_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//Datos//Raw_data//sports//1.txt\n",
      "..//Datos//Raw_data//sports//2.txt\n",
      "..//Datos//Raw_data//sports//3.txt\n",
      "..//Datos//Raw_data//sports//4.txt\n",
      "..//Datos//Raw_data//sports//5.txt\n",
      "..//Datos//Raw_data//sports//6.txt\n",
      "..//Datos//Raw_data//sports//7.txt\n",
      "..//Datos//Raw_data//sports//8.txt\n",
      "..//Datos//Raw_data//sports//9.txt\n",
      "..//Datos//Raw_data//sports//10.txt\n",
      "..//Datos//Raw_data//sports//11.txt\n",
      "..//Datos//Raw_data//sports//12.txt\n",
      "..//Datos//Raw_data//sports//13.txt\n",
      "..//Datos//Raw_data//sports//14.txt\n",
      "..//Datos//Raw_data//sports//15.txt\n",
      "..//Datos//Raw_data//sports//16.txt\n",
      "..//Datos//Raw_data//sports//17.txt\n",
      "..//Datos//Raw_data//sports//18.txt\n",
      "..//Datos//Raw_data//sports//19.txt\n",
      "..//Datos//Raw_data//sports//20.txt\n",
      "..//Datos//Raw_data//sports//21.txt\n",
      "..//Datos//Raw_data//sports//22.txt\n",
      "..//Datos//Raw_data//sports//23.txt\n",
      "..//Datos//Raw_data//sports//24.txt\n",
      "..//Datos//Raw_data//sports//25.txt\n",
      "..//Datos//Raw_data//sports//26.txt\n",
      "..//Datos//Raw_data//sports//27.txt\n",
      "..//Datos//Raw_data//sports//28.txt\n",
      "..//Datos//Raw_data//sports//29.txt\n",
      "..//Datos//Raw_data//sports//30.txt\n",
      "..//Datos//Raw_data//sports//31.txt\n",
      "..//Datos//Raw_data//sports//32.txt\n",
      "..//Datos//Raw_data//sports//33.txt\n",
      "..//Datos//Raw_data//sports//34.txt\n",
      "..//Datos//Raw_data//sports//35.txt\n",
      "..//Datos//Raw_data//sports//36.txt\n",
      "..//Datos//Raw_data//sports//37.txt\n",
      "..//Datos//Raw_data//sports//38.txt\n",
      "..//Datos//Raw_data//sports//39.txt\n",
      "..//Datos//Raw_data//sports//40.txt\n",
      "..//Datos//Raw_data//sports//41.txt\n",
      "..//Datos//Raw_data//sports//42.txt\n",
      "..//Datos//Raw_data//sports//43.txt\n",
      "..//Datos//Raw_data//sports//44.txt\n",
      "..//Datos//Raw_data//sports//45.txt\n",
      "..//Datos//Raw_data//sports//46.txt\n",
      "..//Datos//Raw_data//sports//47.txt\n",
      "..//Datos//Raw_data//sports//48.txt\n",
      "..//Datos//Raw_data//sports//49.txt\n",
      "..//Datos//Raw_data//sports//50.txt\n",
      "..//Datos//Raw_data//sports//51.txt\n",
      "..//Datos//Raw_data//sports//52.txt\n",
      "..//Datos//Raw_data//sports//53.txt\n",
      "..//Datos//Raw_data//sports//54.txt\n",
      "..//Datos//Raw_data//sports//55.txt\n",
      "..//Datos//Raw_data//sports//56.txt\n",
      "..//Datos//Raw_data//sports//57.txt\n",
      "..//Datos//Raw_data//sports//58.txt\n",
      "..//Datos//Raw_data//sports//59.txt\n",
      "..//Datos//Raw_data//sports//60.txt\n",
      "..//Datos//Raw_data//health//1.txt\n",
      "..//Datos//Raw_data//health//2.txt\n",
      "..//Datos//Raw_data//health//3.txt\n",
      "..//Datos//Raw_data//health//4.txt\n",
      "..//Datos//Raw_data//health//5.txt\n",
      "..//Datos//Raw_data//health//6.txt\n",
      "..//Datos//Raw_data//health//7.txt\n",
      "..//Datos//Raw_data//health//8.txt\n",
      "..//Datos//Raw_data//health//9.txt\n",
      "..//Datos//Raw_data//health//10.txt\n",
      "..//Datos//Raw_data//health//11.txt\n",
      "..//Datos//Raw_data//health//12.txt\n",
      "..//Datos//Raw_data//health//13.txt\n",
      "..//Datos//Raw_data//health//14.txt\n",
      "..//Datos//Raw_data//health//15.txt\n",
      "..//Datos//Raw_data//health//16.txt\n",
      "..//Datos//Raw_data//health//17.txt\n",
      "..//Datos//Raw_data//health//18.txt\n",
      "..//Datos//Raw_data//health//19.txt\n",
      "..//Datos//Raw_data//health//20.txt\n",
      "..//Datos//Raw_data//health//21.txt\n",
      "..//Datos//Raw_data//health//22.txt\n",
      "..//Datos//Raw_data//health//23.txt\n",
      "..//Datos//Raw_data//health//24.txt\n",
      "..//Datos//Raw_data//health//25.txt\n",
      "..//Datos//Raw_data//health//26.txt\n",
      "..//Datos//Raw_data//health//27.txt\n",
      "..//Datos//Raw_data//health//28.txt\n",
      "..//Datos//Raw_data//health//29.txt\n",
      "..//Datos//Raw_data//health//30.txt\n",
      "..//Datos//Raw_data//health//31.txt\n",
      "..//Datos//Raw_data//health//32.txt\n",
      "..//Datos//Raw_data//health//33.txt\n",
      "..//Datos//Raw_data//health//34.txt\n",
      "..//Datos//Raw_data//health//35.txt\n",
      "..//Datos//Raw_data//health//36.txt\n",
      "..//Datos//Raw_data//health//37.txt\n",
      "..//Datos//Raw_data//health//38.txt\n",
      "..//Datos//Raw_data//health//39.txt\n",
      "..//Datos//Raw_data//health//40.txt\n",
      "..//Datos//Raw_data//health//41.txt\n",
      "..//Datos//Raw_data//health//42.txt\n",
      "..//Datos//Raw_data//health//43.txt\n",
      "..//Datos//Raw_data//health//44.txt\n",
      "..//Datos//Raw_data//health//45.txt\n",
      "..//Datos//Raw_data//health//46.txt\n",
      "..//Datos//Raw_data//health//47.txt\n",
      "..//Datos//Raw_data//health//48.txt\n",
      "..//Datos//Raw_data//health//49.txt\n",
      "..//Datos//Raw_data//health//50.txt\n",
      "..//Datos//Raw_data//health//51.txt\n",
      "..//Datos//Raw_data//health//52.txt\n",
      "..//Datos//Raw_data//health//53.txt\n",
      "..//Datos//Raw_data//health//54.txt\n",
      "..//Datos//Raw_data//health//55.txt\n",
      "..//Datos//Raw_data//health//56.txt\n",
      "..//Datos//Raw_data//health//57.txt\n",
      "..//Datos//Raw_data//health//58.txt\n",
      "..//Datos//Raw_data//health//59.txt\n",
      "..//Datos//Raw_data//health//60.txt\n",
      "..//Datos//Raw_data//science//1.txt\n",
      "..//Datos//Raw_data//science//2.txt\n",
      "..//Datos//Raw_data//science//3.txt\n",
      "..//Datos//Raw_data//science//4.txt\n",
      "..//Datos//Raw_data//science//5.txt\n",
      "..//Datos//Raw_data//science//6.txt\n",
      "..//Datos//Raw_data//science//7.txt\n",
      "..//Datos//Raw_data//science//8.txt\n",
      "..//Datos//Raw_data//science//9.txt\n",
      "..//Datos//Raw_data//science//10.txt\n",
      "..//Datos//Raw_data//science//11.txt\n",
      "..//Datos//Raw_data//science//12.txt\n",
      "..//Datos//Raw_data//science//13.txt\n",
      "..//Datos//Raw_data//science//14.txt\n",
      "..//Datos//Raw_data//science//15.txt\n",
      "..//Datos//Raw_data//science//16.txt\n",
      "..//Datos//Raw_data//science//17.txt\n",
      "..//Datos//Raw_data//science//18.txt\n",
      "..//Datos//Raw_data//science//19.txt\n",
      "..//Datos//Raw_data//science//20.txt\n",
      "..//Datos//Raw_data//science//21.txt\n",
      "..//Datos//Raw_data//science//22.txt\n",
      "..//Datos//Raw_data//science//23.txt\n",
      "..//Datos//Raw_data//science//24.txt\n",
      "..//Datos//Raw_data//science//25.txt\n",
      "..//Datos//Raw_data//science//26.txt\n",
      "..//Datos//Raw_data//science//27.txt\n",
      "..//Datos//Raw_data//science//28.txt\n",
      "..//Datos//Raw_data//science//29.txt\n",
      "..//Datos//Raw_data//science//30.txt\n",
      "..//Datos//Raw_data//science//31.txt\n",
      "..//Datos//Raw_data//science//32.txt\n",
      "..//Datos//Raw_data//science//33.txt\n",
      "..//Datos//Raw_data//science//34.txt\n",
      "..//Datos//Raw_data//science//35.txt\n",
      "..//Datos//Raw_data//science//36.txt\n",
      "..//Datos//Raw_data//science//37.txt\n",
      "..//Datos//Raw_data//science//38.txt\n",
      "..//Datos//Raw_data//science//39.txt\n",
      "..//Datos//Raw_data//science//40.txt\n",
      "..//Datos//Raw_data//science//41.txt\n",
      "..//Datos//Raw_data//science//42.txt\n",
      "..//Datos//Raw_data//science//43.txt\n",
      "..//Datos//Raw_data//science//44.txt\n",
      "..//Datos//Raw_data//science//45.txt\n",
      "..//Datos//Raw_data//science//46.txt\n",
      "..//Datos//Raw_data//science//47.txt\n",
      "..//Datos//Raw_data//science//48.txt\n",
      "..//Datos//Raw_data//science//49.txt\n",
      "..//Datos//Raw_data//science//50.txt\n",
      "..//Datos//Raw_data//science//51.txt\n",
      "..//Datos//Raw_data//science//52.txt\n",
      "..//Datos//Raw_data//science//53.txt\n",
      "..//Datos//Raw_data//science//54.txt\n",
      "..//Datos//Raw_data//science//55.txt\n",
      "..//Datos//Raw_data//science//56.txt\n",
      "..//Datos//Raw_data//science//57.txt\n",
      "..//Datos//Raw_data//science//58.txt\n",
      "..//Datos//Raw_data//science//59.txt\n",
      "..//Datos//Raw_data//science//60.txt\n",
      "..//Datos//Raw_data//politics//1.txt\n",
      "..//Datos//Raw_data//politics//2.txt\n",
      "..//Datos//Raw_data//politics//3.txt\n",
      "..//Datos//Raw_data//politics//4.txt\n",
      "..//Datos//Raw_data//politics//5.txt\n",
      "..//Datos//Raw_data//politics//6.txt\n",
      "..//Datos//Raw_data//politics//7.txt\n",
      "..//Datos//Raw_data//politics//8.txt\n",
      "..//Datos//Raw_data//politics//9.txt\n",
      "..//Datos//Raw_data//politics//10.txt\n",
      "..//Datos//Raw_data//politics//11.txt\n",
      "..//Datos//Raw_data//politics//12.txt\n",
      "..//Datos//Raw_data//politics//13.txt\n",
      "..//Datos//Raw_data//politics//14.txt\n",
      "..//Datos//Raw_data//politics//15.txt\n",
      "..//Datos//Raw_data//politics//16.txt\n",
      "..//Datos//Raw_data//politics//17.txt\n",
      "..//Datos//Raw_data//politics//18.txt\n",
      "..//Datos//Raw_data//politics//19.txt\n",
      "..//Datos//Raw_data//politics//20.txt\n",
      "..//Datos//Raw_data//politics//21.txt\n",
      "..//Datos//Raw_data//politics//22.txt\n",
      "..//Datos//Raw_data//politics//23.txt\n",
      "..//Datos//Raw_data//politics//24.txt\n",
      "..//Datos//Raw_data//politics//25.txt\n",
      "..//Datos//Raw_data//politics//26.txt\n",
      "..//Datos//Raw_data//politics//27.txt\n",
      "..//Datos//Raw_data//politics//28.txt\n",
      "..//Datos//Raw_data//politics//29.txt\n",
      "..//Datos//Raw_data//politics//30.txt\n",
      "..//Datos//Raw_data//politics//31.txt\n",
      "..//Datos//Raw_data//politics//32.txt\n",
      "..//Datos//Raw_data//politics//33.txt\n",
      "..//Datos//Raw_data//politics//34.txt\n",
      "..//Datos//Raw_data//politics//35.txt\n",
      "..//Datos//Raw_data//politics//36.txt\n",
      "..//Datos//Raw_data//politics//37.txt\n",
      "..//Datos//Raw_data//politics//38.txt\n",
      "..//Datos//Raw_data//politics//39.txt\n",
      "..//Datos//Raw_data//politics//40.txt\n",
      "..//Datos//Raw_data//politics//41.txt\n",
      "..//Datos//Raw_data//politics//42.txt\n",
      "..//Datos//Raw_data//politics//43.txt\n",
      "..//Datos//Raw_data//politics//44.txt\n",
      "..//Datos//Raw_data//politics//45.txt\n",
      "..//Datos//Raw_data//politics//46.txt\n",
      "..//Datos//Raw_data//politics//47.txt\n",
      "..//Datos//Raw_data//politics//48.txt\n",
      "..//Datos//Raw_data//politics//49.txt\n",
      "..//Datos//Raw_data//politics//50.txt\n",
      "..//Datos//Raw_data//politics//51.txt\n",
      "..//Datos//Raw_data//politics//52.txt\n",
      "..//Datos//Raw_data//politics//53.txt\n",
      "..//Datos//Raw_data//politics//54.txt\n",
      "..//Datos//Raw_data//politics//55.txt\n",
      "..//Datos//Raw_data//politics//56.txt\n",
      "..//Datos//Raw_data//politics//57.txt\n",
      "..//Datos//Raw_data//politics//58.txt\n",
      "..//Datos//Raw_data//politics//59.txt\n",
      "..//Datos//Raw_data//politics//60.txt\n",
      "4\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "clases, documentos = cargar_txts(noticias_dataframe)\n",
    "print(len(clases))\n",
    "print(len(documentos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos los tipos de datos de las columnas de nuestro dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(noticias_dataframe))\n",
    "# print(type(df_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El lateral neerlandés regaló dos asistencias, marcó el 1-3... y el delantero azulgrana bailó con la defensa estadounidense para clasificar a la Oranje a los cuartos de final del Mundial\n",
      "\"En Países Bajos aprendí mucho, tomé muchos conceptos de fútbol\". Gregg Berhalter, seleccionador de Estados Unidos, aseguró en la previa del partido que se inspiró en el fútbol neerlandés para fijar las bases de su ideario como entrenador. Unos conceptos futbolísticos que se dejaron ver en los primeros compases del partido, hasta que Memphis Depay decidió romper el espejismo impuesto por la caballería yankee.\n",
      "Averiguaron la forma en la que tenían que atacar a Países Bajos para desarmar su entramado defensivo pero Pulisic, que no tuvo su día, no consiguió mandar al fondo de la red ni una de las dos ocasiones que tuvo en la primera parte. Una de ellas tardará mucho tiempo en olvidarla. \n",
      "Instaurados en el bloque bajo, los hombres de Louis van Gaal dieron una auténtica lección de cómo un equipo tiene que atacar el espacio con sus contras. El '10' bajaba a recibir, 'liberaba' de sus funciones a los centrocampistas... e incluso era capaz de llegar al área para generar todo el peligro del conjunto neerlandés. Y en la primera que cazó dentro del área, Depay no perdonó para certifican que el 'soccer' todavía está lejos del modelo de fútbol de Países Bajos.\n",
      "Dos cabalgadas de Dumfries fueron más que suficientes para romper a toda la defensa de Estados Unidos: la primera la mandó Depay al fondo de la red y en el tercer pase de la muerte del lateral en la primera parte, el segundo lo cortó Adams con muchos problemas, apareció Blind para firmar el 2-0 justo antes del descanso. Dos acciones calcadas que ponían a la Oranje con pie y medio en los cuartos de final del Mundial de Qatar 2022.\n",
      "Memphis aprovechaba con su tanto para deshacer el empate con Klass-Jan Huntelaar y convertirse así en el segundo máximo goleador de la selección neerlandesa, solo superado por Robin Van Persie (50). \n",
      "Y cuando Países Bajos disfrutaba de la segunda parte, apareció Wright para ponerle un poco de emoción al partido con una acción de ilusionista. El delantero estadounidense se inventó un escorzo de película para mandar el balón al fondo de la red con un taconazo brillante. El 'Capitán América' colgaba el balón en el área pequeña y el '19' tiraba de imaginación para firmar el 1-2. \n",
      "Sin embargo, la rebelión en la que Estados Unidos parecía buscar la independencia duró tan sólo 5 minutos. Dumfries, MVP del partido, apareció primero en su área sacando un disparo de Wright  en la línea de gol y sorprendía en la jugada siguiente para finiquitar el partido con el 3-1. Balón colgado de Blind al segundo palo y el lateral, completamente sólo, empalaba a la perfección el esférico para cerrar la clasificación de la la Oranje a los cuartos de final del Mundial. El show terminó siendo naranja. \n"
     ]
    }
   ],
   "source": [
    "print(documentos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_dataframe[\"docs\"] = documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'category', 'n_doc', 'title', 'path', 'link', 'docs'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Miramos los nombres\n",
    "noticias_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un duplicado de nuestro dataframe para reducir el tamaño y trabajar de forma más cómoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_dataframe2 = noticias_dataframe.loc[:,['title', 'category','docs']]\n",
    "noticias_dataframe2=noticias_dataframe2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que el número de instancias sigue siendo el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 7)\n",
      "(240, 3)\n"
     ]
    }
   ],
   "source": [
    "print(noticias_dataframe.shape)\n",
    "print(noticias_dataframe2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos las posibles categorías de nuestros textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sports', 'health', 'science', 'politics']\n"
     ]
    }
   ],
   "source": [
    "clases = pd.unique(noticias_dataframe2['category']).tolist()\n",
    "print(clases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y comprobamos si las categorías están balanceadas en cuanto a peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  docs\n",
       "category             \n",
       "health       60    60\n",
       "politics     60    60\n",
       "science      60    60\n",
       "sports       60    60"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frecuencias = noticias_dataframe2.groupby('category').count()\n",
    "frecuencias = frecuencias.sort_values('title',ascending=False)\n",
    "\n",
    "frecuencias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, todas las clases tienen el mismo peso, es decir, tienen el mismo numero de noticas. Tenemos un conjunto de datos homogeneo para el cual hacer la prediccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PRE-PROCESADO\n",
    "Realizaremos el siguiente procesado:\n",
    "- Separar el texto en *tokens*\n",
    "- Eliminar los *tokens* de tipo *stop-word*, signos de puntuación, signos especiales o espacios\n",
    "- Lematizar el texto\n",
    "- Introducimos un espacio después de determinados signos de puntuación (\".\", \"?\", \"%\") para que el tokenizado sea correcto\n",
    "- Filtramos los *tokens* con una longitud de 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/models/es\n",
    "nlp = spacy.load(\"es_core_news_lg\") #Mejor modelo optimizado para la CPU\n",
    "\n",
    "#definimos función de normalizado\n",
    "def normaliza(texto):\n",
    "    texto = re.sub(r\"(\\.)|(\\?)|(\\%)\", r\"\\1 |\\2 |\\3 \", texto) #añadimos un espacio después de \".\" y \"?\"\n",
    "    doc = nlp(texto)\n",
    "    tokens = [t for t in doc if\n",
    "                        len(t.text)>1 and\n",
    "                       not t.is_stop and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]#filtramos los tokens que nos interesan\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        palabras.append(t.lemma_) #añadimos lema\n",
    "    salida = ' '.join(palabras)#junta todos los tokens en un string\n",
    "    \n",
    "    return salida\n",
    "\n",
    "#funcion para quitar acentos y caracteres no ASCII:\n",
    "\n",
    "def remove_accents(input_str):     \n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)     \n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')     \n",
    "    return only_ascii.decode(\"utf-8\", 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos que funciona con el elemento 0 de noticia (\"noticia\")\n",
    "print(df2['docs'][0])\n",
    "print(\"-\"*140)\n",
    "normaliza(df2['docs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos que funciona con el elemento 2 de noticia (\"docs\")\n",
    "print(df2['docs'][2])\n",
    "print(\"-\"*140)\n",
    "normaliza(df2['docs'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de corpus y labels \n",
    "df2[\"corpus\"] = df2['docs'] + df2['title']\n",
    "corpus = df2[\"corpus\"].tolist()\n",
    "\n",
    "labels_posibles = pd.unique(df2['category']).tolist()\n",
    "labels = df2['category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_r=ruta+\"/Prediccion\"\n",
    "\n",
    "os.mkdir(prediccion_r)\n",
    "\n",
    "df2.to_csv(prediccion_r+'/training.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cuantas observaciones en total tenemos.\n",
    "print(f'\\nTamaño  TOTAL: {len(corpus)}')\n",
    "print(f'Tamaño de clase TOTAL: {len(labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos 5000 muestras del cojunto de datos total\n",
    "# corpus_sm, labels_sm = resample(corpus, labels, n_samples=5000, replace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separacion del conjunto de datos P5\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(corpus, labels, test_size = 0.30, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "print(f'\\nTamaño de TRAIN: {len(train_corpus)}')\n",
    "print(f'Tamaño de clase TRAIN: {len(train_labels)}')\n",
    "\n",
    "print(f'\\nTamaño de TEST: {len(test_corpus)}')\n",
    "print(f'Tamaño de clase TEST: {len(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los docss y los guardamos como una lista en lugar de generator porque \n",
    "#lo tenemos que múltiples veces y no queremos tener que normalizar todo el corpus cada vez.\n",
    "norm_train_corpus = list(map(normaliza, train_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test_corpus = list(map(normaliza, test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EXTRACCION DE CARACTERISTICAS\n",
    "Instanciamos los vectorizadores para obtener las características BoW y TF-IDF.  \n",
    "Usamos el parámetro max_df=0.9 para eliminar los stop-words como las palabras que aparecen al menos en el 90% de los documentos y el parámetro min_df=0.01 para eliminar las palabras que no aparecen al menos en un 1% de los documentos.\\\n",
    "\n",
    "Usamos el modelo `TfidfTransformer` para calcular la matriz TF-IDF a partir del BoW y no tener que repetir todo el entrenamiento.\n",
    "\n",
    "Para calcular los modelos basados en WV usamos el modelo gloVe pre-entrenado en `spaCy`. Calculamos dos modelos basados en word-vectors:  \n",
    "* El vector promedio de los WV de todos los tokens con el mismo peso para todas las palabras.  \n",
    "* Ponderando el WV de cada palabra por el término de frecuencia inversa de documento (IDF).  \n",
    "\n",
    "Definimos las funciones para calcular estas dos matrices de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW\n",
    "bow_vectorizer = CountVectorizer(min_df=0.01, max_df=0.9)\n",
    "\n",
    "#Tf-idf\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "\n",
    "#Funciones de WV.\n",
    "def averaged_word_vectorizer(corpus):\n",
    "    '''Aplica la función de cálculo del WE promedio a todos los\n",
    "    documentos del corpus (cada doc es una lista de tokens)'''\n",
    "    features = [nlp(doc).vector\n",
    "                    for doc in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "def tfidf_wtd_avg_word_vectors(doc, word_tfidf_map):\n",
    "    '''Aplica la función de cálculo del WE ponderado por TF-IDF\n",
    "    a un documento (como lista de tokens)'''\n",
    "    tokens = doc.split()\n",
    "\n",
    "    feature_vector = np.zeros((nlp.vocab.vectors_length,),dtype=\"float64\")\n",
    "    wts = 0.      \n",
    "    for word in tokens:\n",
    "        if nlp.vocab[word].has_vector and word_tfidf_map.get(word, 0): #sólo considera palabras conocidas\n",
    "            weighted_word_vector = word_tfidf_map[word] * nlp.vocab[word].vector\n",
    "            wts = wts + 1\n",
    "            feature_vector = np.add(feature_vector, weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector = np.divide(feature_vector, wts)\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus, word_tfidf_map):\n",
    "    '''Aplica la función de cálculo del WE ponderado por TF-IDF a todos los\n",
    "    documentos del corpus (cada doc es una lista de tokens)'''                                       \n",
    "    features = [tfidf_wtd_avg_word_vectors(doc, word_tfidf_map)\n",
    "                    for doc in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# características bag of words\n",
    "bow_train_features = bow_vectorizer.fit_transform(norm_train_corpus)  \n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus) \n",
    "\n",
    "# características tfidf (a partir del BoW)\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(bow_train_features)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(bow_test_features)    \n",
    "\n",
    "# características averaged word vector\n",
    "avg_wv_train_features = averaged_word_vectorizer(norm_train_corpus)                \n",
    "avg_wv_test_features = averaged_word_vectorizer(norm_test_corpus)      \n",
    "\n",
    "# características tfidf weighted averaged word vector\n",
    "word_tfidf_map = {key:value for (key, value) in zip(bow_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_)}\n",
    "\n",
    "tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(norm_train_corpus, word_tfidf_map)\n",
    "\n",
    "tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizer(norm_test_corpus, word_tfidf_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wv_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_wv_train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLASIFICADOR\n",
    "Aplicamos distintos clasificadores a cada modelo para ver cuál funciona mejor con nuestros datos. Primero definimos unas funciones para entrenar y medir el rendimiento de los clasificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Calculamos distintas métricas sobre el\n",
    "    rendimiento del modelo. Devuelve un diccionario\n",
    "    con los parámetros medidos\"\"\"\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': np.round(\n",
    "                        metrics.accuracy_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        3),\n",
    "        'Precision': np.round(\n",
    "                        metrics.precision_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3),\n",
    "    'Recall': np.round(\n",
    "                        metrics.recall_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3),\n",
    "    'F1 Score': np.round(\n",
    "                        metrics.f1_score(true_labels, \n",
    "                                               predicted_labels,\n",
    "                                               average='weighted',\n",
    "                                               zero_division=0),\n",
    "                        3)}\n",
    "                        \n",
    "\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    \"\"\"Función que entrena un modelo de clasificación sobre\n",
    "    un conjunto de entrenamiento, lo aplica sobre un conjunto\n",
    "    de test y devuelve la predicción sobre el conjunto de test\n",
    "    y las métricas de rendimiento\"\"\"\n",
    "    # genera modelo    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predice usando el modelo sobre test\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evalúa rendimiento de la predicción   \n",
    "    metricas = get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions, metricas     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar sobre el conjunto de train y evaluamos en el conjunto de test. Guardamos métricas en una lista y resultados en otra para mostrar resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression(solver='liblinear')\n",
    "modelNB = GaussianNB() #var_smoothing=1e-9\n",
    "modelSVM = SGDClassifier(loss='hinge', max_iter=1000)\n",
    "modelRBFSVM = SVC(gamma='scale', C=2)\n",
    "\n",
    "modelos = [('Logistic Regression', modelLR),\n",
    "           ('Naive Bayes', modelNB),\n",
    "           ('Linear SVM', modelSVM),\n",
    "           ('Gauss kernel SVM', modelRBFSVM)]\n",
    "\n",
    "metricas = []\n",
    "resultados = []\n",
    "\n",
    "# Modelos con características BoW\n",
    "bow_train_features_ = bow_train_features.toarray()\n",
    "bow_test_features_ = bow_test_features.toarray()\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=bow_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} BoW'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "    \n",
    "# Modelos con características TF-IDF\n",
    "tfidf_train_features_ = tfidf_train_features.toarray()\n",
    "tfidf_test_features_ = tfidf_test_features.toarray()\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=tfidf_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} tfidf'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "\n",
    "# Modelos con características averaged word vectors\n",
    "avg_wv_train_features_ = avg_wv_train_features\n",
    "avg_wv_test_features_ = avg_wv_test_features\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=avg_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} averaged'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)\n",
    "\n",
    "# Modelos con características tfidf weighted averaged word vectors\n",
    "tfidf_wv_train_features_ = tfidf_wv_train_features\n",
    "tfidf_wv_test_features_ = tfidf_wv_test_features\n",
    "for m, clf in modelos:\n",
    "    prediccion, metrica = train_predict_evaluate_model(classifier=clf,\n",
    "                                           train_features=tfidf_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "    metrica['modelo']=f'{m} tfidf wv'\n",
    "    resultados.append(prediccion)\n",
    "    metricas.append(metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviertimos la lista de métricas en un DataFrame para observar sus valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = pd.DataFrame(metricas)\n",
    "metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas.to_csv(prediccion_r+'/metricas.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las métricas por `accuracy` y muestra el mejor resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = metricas.sort_values('Accuracy',ascending=False)\n",
    "metricas.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoramos el `accuracy` a partir del juego de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = metricas['modelo'].tolist()\n",
    "\n",
    "mejor = modelos[0]\n",
    "sep = mejor.split(' ')\n",
    "\n",
    "\n",
    "\n",
    "if sep[len(sep)-1]== \"wv\":\n",
    "    mo = ' '.join(sep[:len(sep)-2])\n",
    "    \n",
    "else:\n",
    "    mo = ' '.join(sep[:len(sep)-1])\n",
    "\n",
    "print(mo)\n",
    "    \n",
    "\n",
    "datos = sep[len(sep)-1]\n",
    "print(datos)\n",
    "\n",
    "metricas2 = []\n",
    "resultados = []\n",
    "\n",
    "\n",
    "\n",
    "# DATOS\n",
    "if datos == 'Bow':\n",
    "    train_features_ = bow_train_features.toarray()\n",
    "    test_features_ = bow_test_features.toarray()\n",
    "    \n",
    "if datos == 'tfidf':\n",
    "    train_features_ = tfidf_train_features.toarray()\n",
    "    test_features_ = tfidf_test_features.toarray()\n",
    "    \n",
    "if datos == 'averaged':\n",
    "    train_features_ = avg_wv_train_features\n",
    "    test_features_ = avg_wv_test_features\n",
    "    \n",
    "else: # tfidf wv\n",
    "    train_features_ = tfidf_wv_train_features\n",
    "    test_features_ = tfidf_wv_test_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MODELOS\n",
    "\n",
    "if mo == 'Logistic Regression':\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "    sol = [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"]\n",
    "    \n",
    "    for i in sol:\n",
    "        modelLR = LogisticRegression(solver=i)\n",
    "        prediccion, metrica = train_predict_evaluate_model(classifier=modelLR,\n",
    "                                            train_features=train_features_,\n",
    "                                            train_labels=train_labels,\n",
    "                                            test_features=test_features_,\n",
    "                                            test_labels=test_labels)\n",
    "        metrica['modelo']=f'{i} - Logistic Regression ' + datos\n",
    "        resultados.append(prediccion)\n",
    "        metricas2.append(metrica)\n",
    "    \n",
    "if mo == 'Naive Bayes':\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "    var_smo = [1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10,1e-11,1e-12,1e-13,1e-14,1e-15]\n",
    "    \n",
    "    for i in var_smo:\n",
    "        modelNB = GaussianNB(var_smoothing=i)\n",
    "        prediccion, metrica = train_predict_evaluate_model(classifier=modelLR,\n",
    "                                            train_features=train_features_,\n",
    "                                            train_labels=train_labels,\n",
    "                                            test_features=test_features_,\n",
    "                                            test_labels=test_labels)\n",
    "        metrica['modelo']=f'{i} - Naive Bayes ' + datos\n",
    "        resultados.append(prediccion)\n",
    "        metricas2.append(metrica)\n",
    "    \n",
    "if mo == 'Linear SVM':\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    loss = [\"hinge\", \"log_loss\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\", \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"]\n",
    "\n",
    "    for i in loss:\n",
    "        modelSVM = SGDClassifier(loss=i, max_iter=1000)\n",
    "        prediccion, metrica = train_predict_evaluate_model(classifier=modelLR,\n",
    "                                            train_features=train_features_,\n",
    "                                            train_labels=train_labels,\n",
    "                                            test_features=test_features_,\n",
    "                                            test_labels=test_labels)\n",
    "        metrica['modelo']=f'{i} - Linear SVM ' + datos\n",
    "        resultados.append(prediccion)\n",
    "        metricas2.append(metrica)\n",
    "\n",
    "    \n",
    "else: # Gauss kernel SVM \n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    gamma = [\"scale\", \"auto\"]\n",
    "\n",
    "    for i in gamma:\n",
    "        modelRBFSVM = SVC(gamma=i, C=2)\n",
    "        prediccion, metrica = train_predict_evaluate_model(classifier=modelLR,\n",
    "                                            train_features=train_features_,\n",
    "                                            train_labels=train_labels,\n",
    "                                            test_features=test_features_,\n",
    "                                            test_labels=test_labels)\n",
    "        metrica['modelo']=f'{i} - Gauss kernel SVM ' + datos\n",
    "        resultados.append(prediccion)\n",
    "        metricas2.append(metrica)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviertimos la lista de métricas en un DataFrame para observar sus valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas3 = pd.DataFrame(metricas2)\n",
    "metricas3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las métricas por `accuracy` y muestra el mejor resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas3 = metricas3.sort_values('Accuracy',ascending=False)\n",
    "metricas3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PRODUCCIÓN [PENDIENTE DE CAMBIAR] \n",
    "Cogemos el modelo que mejor funciona y lo aplicamos de forma manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el conjunto total de muestras (`corpus` y `labels`) en entrenamiento y test (30%) y entrenamos el mejor modelo obtenido, para ver si se mejoran los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEJOR MODELO\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(corpus, labels, test_size = 0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos\n",
    "norm_train_corpus = list(map(normaliza, train_corpus))\n",
    "norm_test_corpus = list(map(normaliza, test_corpus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características averaged word vector\n",
    "avg_wv_train_features = averaged_word_vectorizer(norm_train_corpus)                \n",
    "avg_wv_test_features = averaged_word_vectorizer(norm_test_corpus)      \n",
    "avg_wv_train_features_ = avg_wv_train_features\n",
    "avg_wv_test_features_ = avg_wv_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos con características\n",
    "modelRBFSVM = SVC(gamma='scale', C=2)\n",
    "prediccion, metrica = train_predict_evaluate_model(classifier=modelRBFSVM,\n",
    "                                           train_features=avg_wv_train_features_,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features_,\n",
    "                                           test_labels=test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelo Gauss kernel SVM averaged con gamma scale: ')\n",
    "for i in metrica:\n",
    "    print('- ',i, ': ', metrica[i])\n",
    "\n",
    "print('\\nPredicciones:')\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a821d265b19b8e474c372894184ad502aefb1f7882947607cd0ea5f074b097d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
