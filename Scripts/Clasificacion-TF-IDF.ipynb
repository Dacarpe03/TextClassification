{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8dec11c",
   "metadata": {},
   "source": [
    "## Clasificación TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5604d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d082d9",
   "metadata": {},
   "source": [
    "Lo primero que necesitamos es cargar nuestros glosarios de términos para crear nuestro diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9689b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_glosario(categoria):\n",
    "    fname = f\"../Datos/glosario_{categoria}.txt\"\n",
    "    terminos = []\n",
    "    with open(fname, 'r') as f:\n",
    "        termino = f.readline().replace(\"\\n\",\"\")\n",
    "        terminos.append(termino)\n",
    "    return terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b95343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = [\"deportes\", \"salud\", \"ciencia\", \"politica\"]\n",
    "glosarios = {}\n",
    "for categoria in categorias:\n",
    "    glosarios[categoria] = cargar_glosario(categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glosarios_dict = create_dictionary(glosarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54397179",
   "metadata": {},
   "source": [
    "Creamos nuestro diccionario de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142f07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(glosarios):\n",
    "    doc_tokens = [simple_preprocess(corpus) for corpus in dataframe[\"corpus\"]]\n",
    "    dictionary = corpora.Dictionary(doc_tokens)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c437a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_words(docs_list, dictionary):\n",
    "    doc_tokens = [simple_preprocess(corpus) for corpus in docs_list]\n",
    "    dictionary = corpora.Dictionary(doc_tokens)\n",
    "    docs_bow = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokens]\n",
    "    return docs_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae94605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf(docs_bow):\n",
    "    docs_tfidf = models.TfidfModel(docs_bow, smartirs=\"lfc\")\n",
    "    return docs_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf0f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_dict = create_dictionary(noticias_test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f86afe",
   "metadata": {},
   "source": [
    "Ahora es momento de crear una bag of words para cada noticia en base a nuestro diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b8aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_test_dataframe = pd.read_csv(\"../Datos/noticias_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28d80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.15471442329540214), (1, 0.1003955311131111), (2, 0.03557518980057467), (3, 0.1003955311131111), (4, 0.14264881733417556), (5, 0.07132440866708778), (6, 0.05210944191143335), (7, 0.15471442329540214), (8, 0.060986991984878614), (9, 0.05431889218229104), (10, 0.1003955311131111), (11, 0.066645003134445), (12, 0.2595186831673763), (13, 0.1003955311131111), (14, 0.1003955311131111), (15, 0.05431889218229104), (16, 0.066645003134445), (17, 0.066645003134445), (18, 0.07735721164770107), (19, 0.07735721164770107), (20, 0.09010698109161601), (21, 0.07735721164770107), (22, 0.07132440866708778), (23, 0.07132440866708778), (24, 0.1003955311131111), (25, 0.03864952067053617), (26, 0.05210944191143335), (27, 0.05958905176881966), (28, 0.1003955311131111), (29, 0.045053490545808005), (30, 0.07132440866708778), (31, 0.046607563038007234), (32, 0.11917810353763932), (33, 0.03557518980057467), (34, 0.14264881733417556), (35, 0.045053490545808005), (36, 0.1003955311131111), (37, 0.05431889218229104), (38, 0.1003955311131111), (39, 0.05431889218229104), (40, 0.07735721164770107), (41, 0.034643019354758), (42, 0.11917810353763932), (43, 0.08585996989009943), (44, 0.004898992691870083), (45, 0.07132440866708778), (46, 0.026446403514319934), (47, 0.045053490545808005), (48, 0.1003955311131111), (49, 0.034643019354758), (50, 0.14264881733417556), (51, 0.1003955311131111), (52, 0.05958905176881966), (53, 0.05958905176881966), (54, 0.10022150204717266), (55, 0.05678884744407611), (56, 0.07735721164770107), (57, 0.1003955311131111), (58, 0.1003955311131111), (59, 0.03978333095927938), (60, 0.1003955311131111), (61, 0.08585996989009943), (62, 0.1003955311131111), (63, 0.08585996989009943), (64, 0.1003955311131111), (65, 0.1003955311131111), (66, 0.05431889218229104), (67, 0.2575799096702983), (68, 0.12481772989281371), (69, 0.05431889218229104), (70, 0.17171993978019887), (71, 0.3335067354057821), (72, 0.10863778436458207), (73, 0.07132440866708778), (74, 0.05431889218229104), (75, 0.031222402410252276), (76, 0.1003955311131111), (77, 0.1003955311131111), (78, 0.040981964737331594), (79, 0.06282165042468942), (80, 0.08955090594380666), (81, 0.08585996989009943), (82, 0.04828608920167774), (83, 0.08585996989009943), (84, 0.05431889218229104), (85, 0.05011075102358633), (86, 0.03757388068842169), (87, 0.07735721164770107), (88, 0.07956666191855875), (89, 0.066645003134445), (90, 0.07132440866708778), (91, 0.1003955311131111), (92, 0.066645003134445), (93, 0.05210944191143335), (94, 0.066645003134445), (95, 0.03557518980057467), (96, 0.03051792932279634), (97, 0.07735721164770107), (98, 0.027072431558176305), (99, 0.05431889218229104), (100, 0.066645003134445), (101, 0.034643019354758), (102, 0.06282165042468942), (103, 0.05955319189771919), (104, 0.066645003134445), (105, 0.1003955311131111), (106, 0.05958905176881966), (107, 0.08585996989009943), (108, 0.07132440866708778), (109, 0.03375052797866608), (110, 0.05958905176881966), (111, 0.03655073230340963), (112, 0.1003955311131111), (113, 0.03842993351130885), (114, 0.07132440866708778), (115, 0.03289447515577893), (116, 0.05678884744407611), (117, 0.1003955311131111), (118, 0.1003955311131111), (119, 0.08585996989009943), (120, 0.02907112244602332), (121, 0.040981964737331594)]\n"
     ]
    }
   ],
   "source": [
    "docs_bow = create_bag_of_words(noticias_test_dataframe[\"corpus\"].values, noticias_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e7a65",
   "metadata": {},
   "source": [
    "Y con el bag of words podemos crear nuestro modelo tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcafdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = create_tfidf(docs_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565da9b0",
   "metadata": {},
   "source": [
    "Cargamos los glosarios y creamos sus representaciones tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167d523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
