{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de376a82",
   "metadata": {},
   "source": [
    "## EXTRACCIÓN DE CARACTERÍSTICAS\n",
    "Este notebook extrae glosarios para las distintas categorías de texto utilizando la librería gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c891ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d23c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a6f6e92",
   "metadata": {},
   "source": [
    "Cargamos nuestro dataframe de noticias dedicado al entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880846d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_dataframe = pd.read_csv('../Datos/noticias_train.csv')\n",
    "noticias_dataframe_t = pd.read_csv('../Datos/noticias_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "663e45a6",
   "metadata": {},
   "source": [
    "Separamos nuestras noticias en diferentes cojuntos de datos por categoría de noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34d32478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "deportes_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"sports\"]\n",
    "deportes_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "deportes_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"sports\"]\n",
    "deportes_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63238c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 30 to 59\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 30 to 59\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "salud_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"health\"]\n",
    "salud_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "salud_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"health\"]\n",
    "salud_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eae3d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 60 to 89\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 60 to 89\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ciencia_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"science\"]\n",
    "ciencia_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "ciencia_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"science\"]\n",
    "ciencia_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "527ded9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 90 to 119\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 90 to 119\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "politica_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"politics\"]\n",
    "politica_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "politica_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"politics\"]\n",
    "politica_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d50b8",
   "metadata": {},
   "source": [
    "### Extracción de glosario mediante TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15d2f4",
   "metadata": {},
   "source": [
    "La forma más sencilla para obtener nuestro glosario es mediante el esquema *tf-idf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dad4f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrae_glosario_tf_idf(categoria_dataframe, size):\n",
    "    \"\"\" \n",
    "    Funcion para extraer el glosario\n",
    "\n",
    "    - categoria_dataframe: cojunto de datos de una categoriad de noticias\n",
    "    - size: tokens del glosario a mostrar\n",
    "    \"\"\"\n",
    "    # Pre-procesamos el corpus de cada noticia\n",
    "    doc_tokens = [simple_preprocess(corpus) for corpus in categoria_dataframe[\"corpus\"]]\n",
    "\n",
    "    # Hacemos un diccionario. Mapeo de palabras e identificadores de palabra\n",
    "    dictionary = corpora.Dictionary(doc_tokens)\n",
    "\n",
    "    # Convertimos el diccionario al formato BoW\n",
    "    bow_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokens]\n",
    "\n",
    "    # https://radimrehurek.com/gensim/models/tfidfmodel.html\n",
    "    # Implementamos un modelo tf-idf\n",
    "    tfidf = models.TfidfModel(bow_corpus, smartirs=\"lfc\")\n",
    "    bow_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "    # Por cada documento, sacamos un glosario\n",
    "    tfidf_dic = {dictionary.get(id): value for doc in bow_tfidf for id, value in doc}\n",
    "    tfidf_list = [k for k, v in sorted(tfidf_dic.items(), key=lambda item: item[1], reverse = True)]\n",
    "\n",
    "    return tfidf_list[:size]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7df4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glosarios = {'deportes': [],\n",
    "             'salud': [],\n",
    "             'ciencia': [],\n",
    "             'salud': []}\n",
    "\n",
    "glosarios_t = {'deportes': [],\n",
    "            'salud': [],\n",
    "            'ciencia': [],\n",
    "            'salud': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f215781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falso', 'jamas', 'smash', 'mbappe', 'gigante', 'reserva', 'nets', 'carpena', 'djokovic', 'mclaren', 'exencion', 'butler', 'cuento', 'formato', 'campazzo', 'tenerife', 'domenicali', 'booker', 'tatum', 'madrid', 'real', 'premio', 'juventus', 'pagar', 'ronaldo', 'magnussen', 'steiner', 'gavi', 'porra', 'indycar', 'palou', 'gonzalez', 'gonzalo', 'rotacion', 'florentino', 'heredero', 'verdasco', 'enrique', 'luis', 'cristiano', 'cd', 'marbella', 'residencia', 'serbia', 'serbio', 'rosa', 'collins', 'jimmy', 'arabia', 'club']\n",
      "------------------------------------------------------------\n",
      "['seguidor', 'carlos', 'mans', 'warren', 'doncic', 'suarez', 'juancho', 'boston', 'estabilidad', 'horford', 'hernanga', 'mez', 'ferrero', 'enrique', 'grada', 'mirar', 'marko', 'wiggins', 'stakhovsky', 'raptors', 'booker', 'resistencia', 'pts', 'reb', 'colombia', 'garden', 'brooklyn', 'cancha', 'lebron', 'gasto', 'tristeza', 'celtics', 'gimenez', 'sancionar', 'siebert', 'ktm', 'moto', 'dolares', 'rez', 'golden', 'state', 'warriors', 'lesia', 'leclerc', 'ofensivo', 'suns', 'krack', 'james', 'luis', 'aerodinamico']\n"
     ]
    }
   ],
   "source": [
    "glosarios['deportes'] = extrae_glosario_tf_idf(deportes_dataframe, 50)\n",
    "print(glosarios['deportes'])\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['deportes'] = extrae_glosario_tf_idf(deportes_dataframe_t, 50)\n",
    "print(glosarios_t['deportes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85d6dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arterial', 'dash', 'anemia', 'folcodina', 'cafa', 'genital', 'vrs', 'unicef', 'lobo', 'verruga', 'aceite', 'mascarilla', 'pulmonar', 'presion', 'cannabis', 'pet', 'epilepsia', 'zumo', 'quiraorgica', 'afiliado', 'eps', 'ips', 'tc', 'creatividad', 'condiloma', 'marfan', 'manada', 'parasito', 'lavar', 'coosalud']\n",
      "------------------------------------------------------------\n",
      "['strep', 'estigma', 'secuela', 'automatico', 'orina', 'antidepresivo', 'aprovechar', 'nuez', 'entrenar', 'bacteria', 'fruto', 'seco', 'cabello', 'atras', 'sida', 'vih', 'esconder', 'temporada', 'receta', 'congelado', 'alga', 'wakame', 'rehabilitacia', 'adolescente', 'gotlib', 'depresion', 'bronquiolitis', 'cuadro', 'niaos', 'morder']\n"
     ]
    }
   ],
   "source": [
    "glosarios['salud'] = extrae_glosario_tf_idf(salud_dataframe, 30)\n",
    "print(glosarios['salud'])\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['salud'] = extrae_glosario_tf_idf(salud_dataframe_t, 30)\n",
    "print(glosarios_t['salud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0703da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rosell', 'vuelo', 'sentir', 'reyes', 'rufian', 'unilateral', 'multilateral', 'ja', 'sinema', 'benito', 'juarez', 'turismo', 'ucraniano', 'nicolas', 'negativo', 'autoritariaa', 'ruido', 'nero', 'registral', 'demarcacia', 'ex', 'consulta', 'patrimonio', 'perao', 'juventud', 'trias', 'dema', 'coraza', 'ciudadano', 'anunciara']\n",
      "------------------------------------------------------------\n",
      "['silva', 'refera', 'ilacito', 'rodraguez', 'torra', 'insulto', 'urgente', 'esparza', 'mocia', 'animal', 'castillo', 'almeida', 'smith', 'upn', 'cheque', 'ayres', 'concejala', 'mexicano', 'catalunya', 'isabel', 'ndum', 'nduma', 'ahorro', 'nombramiento', 'obrador', 'adjudicacia', 'gandia', 'procesado', 'navarra', 'auxiliar']\n"
     ]
    }
   ],
   "source": [
    "glosarios['politica'] = extrae_glosario_tf_idf(politica_dataframe, 30)\n",
    "print(glosarios['politica'])\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['politica'] = extrae_glosario_tf_idf(politica_dataframe_t, 30)\n",
    "print(glosarios_t['politica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8446b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vacao', 'llama', 'captura', 'cola', 'honor', 'gemanidas', 'banyoles', 'neandertal', 'agujero', 'latigo', 'supersa', 'perfecto', 'regalo', 'bankman', 'fried', 'navidad', 'estampido', 'ftx', 'york', 'menta', 'supermasivo', 'barrera', 'segundo', 'ingeniero', 'magic', 'reencuentro', 'leo', 'nif', 'cernan', 'fauci']\n",
      "------------------------------------------------------------\n",
      "['sal', 'cuantico', 'idioma', 'fraa', 'vacuna', 'isidro', 'santo', 'llnl', 'agujero', 'sonido', 'antageno', 'subtipo', 'quipus', 'congelacia', 'ska', 'ofensivo', 'palabrota', 'canaria', 'relatividad', 'estruendo', 'programador', 'telescopio', 'congelar', 'gripe', 'alineacia', 'almanaque', 'escarcha', 'helada', 'sevilla', 'alphacode']\n"
     ]
    }
   ],
   "source": [
    "glosarios['ciencia'] = extrae_glosario_tf_idf(ciencia_dataframe, 30)\n",
    "print(glosarios['ciencia'])\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['ciencia'] = extrae_glosario_tf_idf(ciencia_dataframe_t, 30)\n",
    "print(glosarios_t['ciencia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfd255",
   "metadata": {},
   "source": [
    "Guardamos los glosarios en .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7c78fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../Datos/Glosarios\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios\")\n",
    "    \n",
    "if os.path.exists(\"../Datos/Glosarios/train\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios/train\")\n",
    "\n",
    "if os.path.exists(\"../Datos/Glosarios/test\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2186b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicial = \"../Datos/Glosarios/train/glosario\"\n",
    "\n",
    "for g in glosarios.items():\n",
    "    tipo = g[0]\n",
    "    fname = f\"{inicial}_{tipo}.txt\"\n",
    "    with open(fname, 'w') as f:\n",
    "        for termino in g[1]:\n",
    "            f.write(termino)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8805c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicial = \"../Datos/Glosarios/test/glosario\"\n",
    "for g in glosarios_t.items():\n",
    "    tipo = g[0]\n",
    "    fname = f\"{inicial}_{tipo}.txt\"\n",
    "    with open(fname, 'w') as f:\n",
    "        for termino in g[1]:\n",
    "            f.write(termino)\n",
    "            f.write('\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clasificacion_3915",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a821d265b19b8e474c372894184ad502aefb1f7882947607cd0ea5f074b097d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
