{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de376a82",
   "metadata": {},
   "source": [
    "## EXTRACCIÓN DE CARACTERÍSTICAS\n",
    "Este notebook extrae glosarios para las distintas categorías de texto utilizando la librería gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77c891ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/Clasificacion_3915/lib/python3.9/site-packages (from gensim) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d23c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a6f6e92",
   "metadata": {},
   "source": [
    "Cargamos nuestro dataframe de noticias dedicado al entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "880846d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_dataframe = pd.read_csv('../Datos/noticias_train.csv')\n",
    "noticias_dataframe_t = pd.read_csv('../Datos/noticias_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "663e45a6",
   "metadata": {},
   "source": [
    "Separamos nuestras noticias en diferentes cojuntos de datos por categoría de noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34d32478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "deportes_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"sports\"]\n",
    "deportes_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "deportes_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"sports\"]\n",
    "deportes_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63238c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 30 to 59\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 30 to 59\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "salud_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"health\"]\n",
    "salud_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "salud_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"health\"]\n",
    "salud_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eae3d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 60 to 89\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 60 to 89\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ciencia_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"science\"]\n",
    "ciencia_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "ciencia_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"science\"]\n",
    "ciencia_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "527ded9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 90 to 119\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 90 to 119\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     30 non-null     int64 \n",
      " 1   category  30 non-null     object\n",
      " 2   n_doc     30 non-null     int64 \n",
      " 3   title     30 non-null     object\n",
      " 4   path      30 non-null     object\n",
      " 5   link      30 non-null     object\n",
      " 6   docs      30 non-null     object\n",
      " 7   corpus    30 non-null     object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "politica_dataframe = noticias_dataframe[noticias_dataframe[\"category\"]==\"politics\"]\n",
    "politica_dataframe.info()\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "politica_dataframe_t = noticias_dataframe_t[noticias_dataframe_t[\"category\"]==\"politics\"]\n",
    "politica_dataframe_t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d50b8",
   "metadata": {},
   "source": [
    "### Extracción de glosario mediante TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15d2f4",
   "metadata": {},
   "source": [
    "La forma más sencilla para obtener nuestro glosario es mediante el esquema *tf-idf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dad4f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrae_glosario_tf_idf(categoria_dataframe, size):\n",
    "    \"\"\" \n",
    "    Funcion para extraer el glosario\n",
    "\n",
    "    - categoria_dataframe: cojunto de datos de una categoriad de noticias\n",
    "    - size: tokens del glosario a mostrar\n",
    "    \"\"\"\n",
    "    # Pre-procesamos el corpus de cada noticia\n",
    "    doc_tokens = [simple_preprocess(corpus) for corpus in categoria_dataframe[\"corpus\"]]\n",
    "\n",
    "    # Hacemos un diccionario. Mapeo de palabras e identificadores de palabra\n",
    "    dictionary = corpora.Dictionary(doc_tokens)\n",
    "\n",
    "    # Convertimos el diccionario al formato BoW\n",
    "    bow_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokens]\n",
    "\n",
    "    # https://radimrehurek.com/gensim/models/tfidfmodel.html\n",
    "    # Implementamos un modelo tf-idf\n",
    "    tfidf = models.TfidfModel(bow_corpus, smartirs=\"lfc\")\n",
    "    bow_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "    # Por cada documento, sacamos un glosario\n",
    "    tfidf_dic = {dictionary.get(id): value for doc in bow_tfidf for id, value in doc}\n",
    "    tfidf_list = [k for k, v in sorted(tfidf_dic.items(), key=lambda item: item[1], reverse = True)]\n",
    "\n",
    "    return tfidf_list[:size]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7df4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glosarios = {'deportes': [],\n",
    "             'salud': [],\n",
    "             'ciencia': [],\n",
    "             'salud': []}\n",
    "\n",
    "glosarios_t = {'deportes': [],\n",
    "            'salud': [],\n",
    "            'ciencia': [],\n",
    "            'salud': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f215781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falso', 'jamas', 'smash', 'mclaren', 'kyrgios', 'tenista', 'ruud', 'respuesta', 'gigante', 'reserva', 'real', 'hernanga', 'mez', 'cuento', 'domenicali', 'chicago', 'ferrero', 'fifa', 'butler', 'formato', 'booker', 'tatum', 'tenerife', 'campazzo', 'descalabro', 'alcaraz', 'juancho', 'magnussen', 'steiner', 'gavi', 'porra', 'gonzalez', 'gonzalo', 'kosmos', 'rotacion', 'gaal', 'austin', 'indycar', 'palou', 'enrique', 'arbitro', 'tristeza', 'uruguayo', 'hijo', 'lesia', 'toronto', 'simplemente', 'rosa', 'cd', 'krack']\n",
      "50\n",
      "------------------------------------------------------------\n",
      "['seguidor', 'mbappe', 'warren', 'doncic', 'estabilidad', 'horford', 'shapovalov', 'cristiano', 'exencion', 'correr', 'carpena', 'enrique', 'luis', 'mans', 'stakhovsky', 'malaga', 'medico', 'booker', 'aliassime', 'auger', 'pts', 'reb', 'nets', 'cantidad', 'juventus', 'ronaldo', 'clippers', 'lebron', 'garden', 'florentino', 'heredero', 'gasto', 'atleta', 'colombia', 'roger', 'verdasco', 'dificil', 'dolares', 'ktm', 'moto', 'pa', 'rez', 'gimenez', 'siebert', 'uruguayo', 'collins', 'rusia', 'marko', 'euros', 'marbella']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "glosarios['deportes'] = extrae_glosario_tf_idf(deportes_dataframe, 50)\n",
    "print(glosarios['deportes'])\n",
    "print(len(glosarios['deportes']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['deportes'] = extrae_glosario_tf_idf(deportes_dataframe_t, 50)\n",
    "print(glosarios_t['deportes'])\n",
    "print(len(glosarios_t['deportes']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85d6dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cafe', 'gripe', 'zumo', 'dash', 'genital', 'orina', 'vrs', 'unicef', 'cancer', 'verruga', 'una', 'pulmonar', 'automatico', 'resfriado', 'vision', 'pet', 'cannabis', 'huevo', 'esconder', 'tc', 'afiliado', 'eps', 'ips', 'creatividad', 'research', 'signo', 'uk', 'vejiga', 'condiloma', 'rehabilitacia', 'alga', 'wakame', 'morder', 'ansiedad', 'coosalud', 'mexico', 'lavar', 'padre', 'recoletas', 'estancamiento', 'mbst', 'esta', 'oms', 'fibrotico', 'vph', 'gen', 'macula', 'oseo', 'vegetal', 'viruela']\n",
      "50\n",
      "------------------------------------------------------------\n",
      "['arterial', 'strep', 'antidepresivo', 'bronquiolitis', 'aprovechar', 'temporada', 'folcodina', 'depresion', 'cafa', 'mascarilla', 'aceite', 'oliva', 'entrenar', 'cabello', 'estigma', 'epilepsia', 'quiraorgica', 'congelado', 'cuadro', 'gotlib', 'marfan', 'manada', 'parasito', 'colapsar', 'intensivo', 'moralesla', 'padres', 'torre', 'pez', 'comida', 'mascaras', 'permafrost', 'ir', 'poveda', 'amigdala', 'hipocampo', 'tpbm', 'viatris', 'expreso', 'crisis', 'saciant', 'vitonica', 'flema', 'gondii', 'gris', 'lader', 'intestinal', 'anpe', 'masticar', 'laser']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "glosarios['salud'] = extrae_glosario_tf_idf(salud_dataframe, 50)\n",
    "print(glosarios['salud'])\n",
    "print(len(glosarios['salud']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['salud'] = extrae_glosario_tf_idf(salud_dataframe_t, 50)\n",
    "print(glosarios_t['salud'])\n",
    "print(len(glosarios_t['salud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0703da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['silva', 'refera', 'torra', 'esparza', 'benito', 'sinema', 'ilacito', 'nicolas', 'isabel', 'nduma', 'almeida', 'demarcacia', 'ayres', 'mexicano', 'rufian', 'autoritariaa', 'cgp', 'adjudicacia', 'obrador', 'vicepresidencia', 'exfuncionario', 'arizona', 'ahorro', 'meloni', 'separado', 'juarez', 'agresion', 'delincuente', 'independiente', 'senador', 'electricidad', 'larsen', 'junts', 'catalunya', 'ndum', 'anunciado', 'gamarra', 'renovacia', 'smith', 'escuchas', 'mitsotakis', 'ebrard', 'embajada', 'estafa', 'falsedad', 'ana', 'lara', 'paases', 'juan', 'lgtbi']\n",
      "50\n",
      "------------------------------------------------------------\n",
      "['rosell', 'vuelo', 'insulto', 'junts', 'precio', 'renovar', 'reyes', 'rufian', 'consulta', 'anunciara', 'sandro', 'monta', 'multilateral', 'turismo', 'partida', 'preguntar', 'ucraniano', 'ndum', 'refera', 'nombramiento', 'ribera', 'falso', 'juventud', 'podem', 'unilateral', 'urgente', 'educativo', 'auxiliar', 'lamite', 'normalidad', 'desbloqueo', 'ministros', 'designacia', 'peticia', 'sortear', 'hipoteca', 'concejal', 'ex', 'midcat', 'diccionario', 'subjetivo', 'republicano', 'actor', 'origen', 'ceuta', 'deu', 'independencia', 'tendrair', 'elevado', 'mwh']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "glosarios['politica'] = extrae_glosario_tf_idf(politica_dataframe, 50)\n",
    "print(glosarios['politica'])\n",
    "print(len(glosarios['politica']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['politica'] = extrae_glosario_tf_idf(politica_dataframe_t, 50)\n",
    "print(glosarios_t['politica'])\n",
    "print(len(glosarios_t['politica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8446b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idioma', 'llnl', 'llama', 'sal', 'grb', 'sapiens', 'cuerpo', 'congelacia', 'antena', 'banyoles', 'neandertal', 'ofensivo', 'palabrota', 'cernan', 'ska', 'canaria', 'congelar', 'bankman', 'fried', 'estruendo', 'programador', 'ftx', 'york', 'fuego', 'sonido', 'isidro', 'menta', 'radiotelescopio', 'estallido', 'trastorno', 'alphacode', 'ba', 'gamma', 'nebulosa', 'smico', 'canarias', 'isla', 'mutacion', 'calificar', 'fonema', 'taco', 'deepmind', 'distrito', 'imputar', 'santo', 'calcio', 'descender', 'puente', 'mandabula', 'martanez']\n",
      "50\n",
      "------------------------------------------------------------\n",
      "['vacuna', 'invierno', 'gripe', 'navidad', 'cuantico', 'captura', 'honor', 'fusia', 'cola', 'fraa', 'gemanidas', 'alcohol', 'latigo', 'supersa', 'regalo', 'tabaco', 'quipus', 'agujero', 'apple', 'antageno', 'subtipo', 'hemofilia', 'estampido', 'sonido', 'ue', 'km', 'fasica', 'galaxia', 'virus', 'magic', 'reencuentro', 'alineacia', 'almanaque', 'escarcha', 'helada', 'tv', 'barrera', 'mola', 'perseidas', 'litio', 'carbono', 'groenlandia', 'sedimento', 'amerizaje', 'cuerda', 'matematica', 'reactor', 'cula', 'supermasivo', 'vehaculo']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "glosarios['ciencia'] = extrae_glosario_tf_idf(ciencia_dataframe, 50)\n",
    "print(glosarios['ciencia'])\n",
    "print(len(glosarios['ciencia']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "glosarios_t['ciencia'] = extrae_glosario_tf_idf(ciencia_dataframe_t, 50)\n",
    "print(glosarios_t['ciencia'])\n",
    "print(len(glosarios_t['ciencia']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfd255",
   "metadata": {},
   "source": [
    "Guardamos los glosarios en .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7c78fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../Datos/Glosarios\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios\")\n",
    "    \n",
    "if os.path.exists(\"../Datos/Glosarios/train\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios/train\")\n",
    "\n",
    "if os.path.exists(\"../Datos/Glosarios/test\") == False:\n",
    "    os.mkdir(\"../Datos/Glosarios/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2186b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicial = \"../Datos/Glosarios/train/glosario\"\n",
    "\n",
    "for g in glosarios.items():\n",
    "    tipo = g[0]\n",
    "    fname = f\"{inicial}_{tipo}.txt\"\n",
    "    with open(fname, 'w') as f:\n",
    "        for termino in g[1]:\n",
    "            f.write(termino)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8805c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicial = \"../Datos/Glosarios/test/glosario\"\n",
    "for g in glosarios_t.items():\n",
    "    tipo = g[0]\n",
    "    fname = f\"{inicial}_{tipo}.txt\"\n",
    "    with open(fname, 'w') as f:\n",
    "        for termino in g[1]:\n",
    "            f.write(termino)\n",
    "            f.write('\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clasificacion_3915",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a821d265b19b8e474c372894184ad502aefb1f7882947607cd0ea5f074b097d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
